{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1.3 Training a Percetron\n",
        "\n"
      ],
      "metadata": {
        "id": "SlsLAbkGxNDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q what is relation between perceptron and hyperplane?\n",
        "\n",
        "The equation of perceptron is equation of plane"
      ],
      "metadata": {
        "id": "NGrjfTe_xZsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q What are advantages of online learning of perceptron?\n",
        "\n",
        "Online learning:learning from one sample at a time\n",
        "\n",
        "1. In online learning there is no need of storing training samples (storage will be costly) \n",
        "2. If samples are changing with time (speech recognition) online learning is better than offline learning\n",
        "3. when physical changes are there(robotic sensors may wear out with time) online learning is useful."
      ],
      "metadata": {
        "id": "xkSsnWRCDsJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q In online learning how error is calculated and weights are adjusted?\n",
        "\n",
        "1. Error is calculated from one sample at a time\n",
        "2. Weights are adjusted to minimise Error calculated\n",
        "3. Both the above steps are repeated for next sample and so on\n",
        "4. If the error is differentiable we use gradient descent."
      ],
      "metadata": {
        "id": "8JjNfm8CFGlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q what is error and online update for regression?\n",
        "\n",
        "***Error:***\n",
        "\n",
        "$E^t(w|x^t, r^t) = \\frac{1}{2}(r^t − y^t)^2 = \\frac{1}{2}[r^t − (w^Tx^t)]^2$\n",
        "\n",
        "t=one instance of sample\n",
        "\n",
        "w=weights\n",
        "\n",
        "x=input\n",
        "\n",
        "r=output\n",
        "\n",
        "y=Estimated output\n",
        "\n",
        "***Online Update***\n",
        "\n",
        "$Δw^t_j= η(r^t − y^t)x^t_j$\n",
        "\n",
        "where j=1..d number of features in  sample t\n",
        "\n",
        "$η=$ learning rate"
      ],
      "metadata": {
        "id": "EKOj8-stGYD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q what is Stochastic Gradient descent?\n",
        "\n",
        "meaning of ***Stochastic***:having a random probability distribution or pattern that may be analysed statistically but may not be predicted precisely.\n",
        "\n",
        "***Stochastic Gradient descent:***Estimating(learning) weights from error and gradually reducing error with time "
      ],
      "metadata": {
        "id": "uCqOD_tGGoY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q For two class classification what are output ,entropy and online update ?\n",
        "\n",
        "***output***\n",
        "\n",
        "$y^t = sigmoid(w^Tx^t)$\n",
        "\n",
        "$where \\ r^t_i= 1 \\ if x^t ∈ C1 \\ and \\ r^t_i= 0 \\ if \\ x^t ∈ C2$\n",
        "\n",
        "***Entropy=Error***\n",
        "\n",
        "$E^t(w|x^t, r^t) = −r^t log y^t − (1 − r^t) log(1 − y^t)$\n",
        "\n",
        "***Online Update***\n",
        "\n",
        "$Δw^t_j= η(r^t − y^t)x^t_j$\n",
        "\n",
        "where j=1..d number of features in  sample t\n",
        "\n",
        "$η=$ learning rate"
      ],
      "metadata": {
        "id": "lZuXxxJiGPNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q For two Multiclass (K>2) classification what are output ,entropy and online update ?\n",
        "\n",
        "***output***\n",
        "\n",
        "$y^t = \\frac{exp \\ w^T_ix^t}{\\Sigma_k exp\\  w^T_kx^t}$\n",
        "\n",
        "$where \\ r^t_i= 1 \\ if x^t ∈ C_i $  and zero otherwise \n",
        "\n",
        "***Entropy=Error***\n",
        "\n",
        "$E^t(w|x^t, r^t) = −\\Sigma_i r^t_i log \\ y^t_i $\n",
        "\n",
        "***Online Update***\n",
        "\n",
        "$Δw^t_{ij}= η(r^t_i − y^t_i)x^t_j$\n",
        "\n",
        "where i=1..K number of Classes\n",
        "\n",
        "where j=1..d number of features in  sample t\n",
        "\n",
        "\n",
        "$η=$ learning rate"
      ],
      "metadata": {
        "id": "yi2g2GhPMq73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q Discuss update formula and learning rate ,Input ,desired output and actual output?\n",
        "\n",
        "***Update = LearningFactor *(DesiredOutput − ActualOutput) *Input***\n",
        "\n",
        "1. (Desired output-Actual output):\n",
        "   \n",
        "   If this is positive weights will be increased\n",
        "\n",
        "   If this is negative weights will be decreased\n",
        "\n",
        "2. Input:\n",
        "   \n",
        "   If this is large weights will be increased\n",
        "\n",
        "   If this is near to zero  no influence on weights \n",
        "\n",
        "3. learning rate:\n",
        "   \n",
        "   If this is large learning depends too much on samples\n",
        "\n",
        "   If this is small many updates are required\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "6z2LZBstX6zb"
      }
    }
  ]
}