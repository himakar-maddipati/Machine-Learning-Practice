{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Q.what are projection methods used for ?\n",
        "\n",
        "For mapping input dimensions d to k(k<d)"
      ],
      "metadata": {
        "id": "C4oK3yOCTcXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q.what is matrix projection formula of x in the direction of w?\n",
        "\n",
        "$Z=W^T.x$"
      ],
      "metadata": {
        "id": "j22l15D8US6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q principal Principal component analysis (PCA) is supervised or  unsupervised method?\n",
        "\n",
        "Unsupervised as it uses only input features only"
      ],
      "metadata": {
        "id": "59tEWSDWUmRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q What is criteria for maximization in PCA?\n",
        "\n",
        "Variance"
      ],
      "metadata": {
        "id": "LGT_jcvFVJct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q In PCA samples are projected onto _____________\n",
        "\n",
        "unit vectors $W=[w_1,w_2]$"
      ],
      "metadata": {
        "id": "11s2sa3ZV0Qw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q In PCA the projections of samples on Principal component should show maximum or minimum varaiance?\n",
        "\n",
        "Maximum"
      ],
      "metadata": {
        "id": "EQ1t39aOWDnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q Why we take $||w_1||=1$(magnitude of vector along Principal component)?\n",
        "\n",
        "To make direction important and to get unique solution"
      ],
      "metadata": {
        "id": "X8zLvSBTXTlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Normal Distribution of  sample and its Projection  \n",
        "\n",
        "let sample X follow normal distribution\n",
        "$  X \\sim \\mathcal{N_d}(\\mu,\\,\\sigma^{2})\\,$\n",
        "\n",
        "\n",
        "Let W be projections  matrix of X $W \\in R^d$\n",
        "\n",
        "$ W^T x = w_1x_1 + w_2x_2 +Â· Â· Â·+w_dx_d âˆ¼\\mathcal{N}(w^TÎ¼,w^TÎ£w)$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jl2jFUlemg16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.Find Estimate $E[W^T x]$ and Variance  Var($W^T x$) of Projection($W$)\n",
        "\n",
        "\n",
        "\n",
        "$E[w^T x] = w^TE[x] = w^TÎ¼$\n",
        "\n",
        "**Above equation tells that estimate of projection depends on mean of sample**\n",
        "\n",
        "$Var(w^T x) = E[(w^T x âˆ’ w^TÎ¼)^2] = E[(w^T x âˆ’ w^TÎ¼)(w^T x âˆ’ w^TÎ¼)]$\n",
        "\n",
        "$Var(w^T x)= E[w^T (x âˆ’ Î¼)(x âˆ’ Î¼)^Tw] = w^T E[(x âˆ’ Î¼)(x âˆ’ Î¼)^T ]w$\n",
        "\n",
        "$Var(w^T x) = w^TÎ£w$\n",
        "\n",
        "**Above equation tells that Variance  of projection depends on variance of sample**\n",
        "\n"
      ],
      "metadata": {
        "id": "desuLG0xuXSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q How  lagrangian multiplyer is used  for maximisation \n",
        " \n",
        "https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-examples"
      ],
      "metadata": {
        "id": "MTOJyPUxdyJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Properties of orthogonal Matrix\n",
        "\n",
        "https://www.nagwa.com/en/explainers/476190725258/\n",
        "\n",
        "https://www.algebrapracticeproblems.com/orthogonal-matrix/\n",
        "\n",
        "Properties:\n",
        "\n",
        "### 1.square matrix A is orthogonal if $A^TA=I_n$,where is $I$ is  ð‘›Ã—ð‘›identity matrix.\n",
        "### 2.For a matrix ð´  to be orthogonal, determinent |ð´|=Â±1\n",
        "### 3. if $c_1,c_2....c_n$ are columns of square matrix A if $c_i.c_i=1$ for all i=1,2...n and $c_i.c_j=0$ for $ i \\neq j $ then A is orthogonal\n",
        "### 4.if A and B are orthogonal to each other then $A^T.B=0$"
      ],
      "metadata": {
        "id": "9i0G1Qx_dzNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Derive First principal component for projections\n",
        "\n",
        "***Formulate Maximisation of Variance along vector $w1$ as Lagrangian problem***\n",
        "\n",
        "we know\n",
        "\n",
        " ***Var($Z_1$)=$w^T_1Î£w_1$***\n",
        "\n",
        " Constraint is:\n",
        "\n",
        " $w^T_1w_1=1$  as $w_1$ is orthogonal matrix with norm=1(unit vector)\n",
        "\n",
        " ***Lagrangian formula is: Var($z_1$)-Î±(constraint)***\n",
        "\n",
        " ${max}_{w_1} w^T_1Î£w_1 âˆ’ Î±(w^T_1w_1âˆ’ 1)$\n",
        "\n",
        " Taking the derivative with respect to $w_1$ and setting it equal to 0, we\n",
        "have\n",
        "$2Î£w_1 âˆ’ 2Î±w_1 = 0$\n",
        "\n",
        "$ Î£w_1 = Î±w_1$\n",
        "\n",
        "multiply both sides by $w^T_1$\n",
        "\n",
        "$w^T_1Î£w_1 = Î±w^T_1=\\alpha$\n",
        "\n",
        "From  above equation $w_1$ is an eigenvector of Î£ and $ Î»_1=Î± $ the corresponding eigenvalue.\n",
        "Because we want to maximize we choose the eigenvector with the largest eigenvalue for the variance\n",
        "\n",
        "Another relation between $\\Sigma\\,w_1,\\alpha\\$ to find diagonal variance vector\n",
        "\n",
        "multiply both sides by $w^T_1$\n",
        "\n",
        "$w^T_1Î£w_1 = Î±w^T_1w_1=\\alpha$\n",
        "\n",
        "$w^T_1Î£w_1 = \\alpha$\n"
      ],
      "metadata": {
        "id": "P4pflwr0hF2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Derive Second principal component for projections\n",
        "\n",
        "second principal component $w_2$ will be orthogonal to $w_1$\n",
        "\n",
        "$\\therefore w^T_2w_1=0$\n",
        "\n",
        "***Formulate Maximisation of Variance along vector $w2$ as Lagrangian problem***\n",
        "\n",
        "we know\n",
        "\n",
        " ***Var($Z_2$)=$w^T_2Î£w_2$***\n",
        "\n",
        " Constraints are:\n",
        "\n",
        " $w^T_2w_2=1$  as $w_2$ is orthogonal matrix with norm=1(unit vector)\n",
        "\n",
        "  $ w^T_2w_1=0$ as $w_2$ is orthogonal to $w_1$\n",
        "\n",
        "  ***Lagrangian formula is: Var($z_2$)-Î±(constraint1)-Î²(constraint2)***\n",
        "\n",
        "\n",
        "\n",
        " ${max}_{w_2} w^T_2Î£w_2 âˆ’ Î±(w^T_2w_2âˆ’ 1)-Î²(w^T_2w_1-0)$\n",
        "\n",
        " Taking the derivative with respect to $w_2$ and setting it equal to 0, we\n",
        "have\n",
        "$2Î£w_2 âˆ’ 2Î±w_2-Î²w_1 = 0$\n",
        "\n",
        "\n",
        "\n",
        "multiply both sides by $w^T_2$\n",
        "\n",
        "$2w^T_2Î£w_2 âˆ’ 2Î±w^T_2w_2-Î²w^T_2w_1 = 0$\n",
        "\n",
        "because $ w^T_2w_1=0$ the above equation becomes:\n",
        "\n",
        "$2w^T_2Î£w_2 âˆ’ 2Î±w^T_2w_2= 0$\n",
        "\n",
        "$\\therefore Î£w_2 = Î±w_2$\n",
        "\n",
        "From  above equation $w_2$ is an eigenvector of Î£ and $Î»_2=\\alpha$ the corresponding eigenvalue.\n",
        "\n",
        "relationship of eigen values\n",
        "\n",
        "***$\\lambda_1 >\\lambda_2$***\n",
        "\n",
        "relationship of eigen vectors\n",
        "\n",
        "***$w_1 >w_2$***"
      ],
      "metadata": {
        "id": "KlQ2sMCNlYnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Alternative derivation for Projections\n",
        "\n",
        "Let A=input array with each element substracted with mean\n",
        "\n",
        "then Covariance of A is $Î£$=$A^T.A$\n",
        "\n",
        "Length of projections=P=A.W\n",
        "\n",
        "We know variance along P is $Ïƒ^2=P^T.P$ \n",
        "\n",
        "variance along projection line=$Ïƒ^2=P^T.P=(AW)^T.AW=W^T(A^T.A)W=W^T\\Sigma W$\n",
        "\n",
        "\n",
        " We have to maximise variance along P which is following equation\n",
        "\n",
        "$Ïƒ^2=W^T\\Sigma W$\n",
        "\n",
        "substituting  $Î£W=Î»W$\n",
        "\n",
        "$Ïƒ^2=W^T\\lambda W$\n",
        "\n",
        "As $w_1 ,w_2$ are orthogonal we have following relations\n",
        "\n",
        "$w^T_1.w_1=1$ and $w^T_2.w_2=1$ and  $w_1.w_2=0$\n",
        "\n",
        "$Ïƒ^2=W^T\\lambda W=\\lambda W^TW=Î»$\n",
        "\n",
        "****Therefore variance along P is eigen values array $\\lambda=[\\lambda_1,\\lambda_2]$ for 2 dimensions****\n",
        "\n",
        "****Therefore variance along Eigen vectors(W=[$w_1,w_2$]) is eigen values array $\\lambda=[\\lambda_1,\\lambda_2]$ for two dimensions****\n",
        "\n",
        "For 2dimensions  the first eigenvector  explains 95% of the total variance.\n",
        "\n",
        "So Reduced Dataset=projection of A onto $w_1$=$A.w_1$\n",
        "\n"
      ],
      "metadata": {
        "id": "JP7Y9zCnwXMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.Procedure for Projection calculation\n",
        "\n",
        "1. Mean-center the data by subtracting each feature from its mean.\n",
        "2. Find the covariance matrix of the centered data $Î£ =(A^T)A$\n",
        "3. Apply eigen-decomposition to $Î£$.\n",
        "4. Order the eigenvectors w.r.t the eigenvalues in descending order.\n",
        "5. Choose the first n eigenvectors that explain 95% of the total variance.\n",
        "6. Create a matrix W, where each column is one of the chosen vectors.\n",
        "7. Project the dat onto the subspace defined by:\n",
        "\n",
        "Reduced Dataset=$A.W$"
      ],
      "metadata": {
        "id": "wKObi8dA5BOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. properties of Projections(Eigen vectors)\n",
        "\n",
        "### 1.because $Î£ \\,$is symmetric, for two different eigenvalues, the eigenvectors are orthogonal.($w_1 ,w_2$ are orthogonal)\n",
        "\n",
        "### 2.If Î£ is positive definite ($x^TÎ£x > 0$, for all nonnull x), then all its eigenvalues are positive.\n",
        "\n",
        "### 3.Since $Î£$ is singular (singular means determinent value =0) then its rank, the effective dimensionality, is k with k < d and $Î»_i$, i = k + 1, . . . , d are 0\n",
        "\n",
        "### 4.The k eigenvectors with nonzero eigenvalues are the dimensions of the reduced space\n",
        "\n",
        "### 5.The first eigenvector (the one with the largest eigenvalue), w1, namely, the principal component, explains the largest part of the variance; the second explains the second largest; and so on."
      ],
      "metadata": {
        "id": "py6uPcwD0i9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.Given $Î£$ find eigen vectors and eigen values\n",
        "\n",
        "$ Î£=\n",
        "\\begin{bmatrix}\n",
        " 6 & 4\\\\ \n",
        " 4 & 5\\\\\n",
        " \\end{bmatrix}$\n",
        "\n",
        "we know\n",
        "\n",
        "$ Î£w = \\lambda w$\n",
        "\n",
        "$\\therefore Î£w-\\lambda w=0$\n",
        "\n",
        "since $w$ is nonzero we can write above equation as follows:\n",
        "\n",
        "$\\therefore determinant \\, of \\,|Î£-\\lambda I|=0$\n",
        "\n",
        "$ Î£=\n",
        "\\begin{bmatrix}\n",
        " 6-\\lambda & 4\\\\ \n",
        " 4 & 5-\\lambda\\\\\n",
        " \\end{bmatrix}=0$\n",
        "\n",
        " $\\therefore \\,$($6-\\lambda$)($5-\\lambda$)-(4)(4)=0\n",
        "\n",
        "$\\therefore \\,\\lambda^2-11\\lambda+14=0$\n",
        "\n",
        "***solving quadratic equation the eigen values are $\\lambda_1=9.5,\\ \\lambda_2=1.5$***\n",
        "\n",
        "because $wÎ£=\\lambda w$ we can write as:\n",
        "\n",
        "$ Î£=\n",
        "\\begin{bmatrix}\n",
        " 6 & 4\\\\ \n",
        " 4 & 5\\\\\n",
        " \\end{bmatrix}\\begin{bmatrix}\n",
        " x\\\\ \n",
        " y\\\\\n",
        " \\end{bmatrix}=\\lambda_1\\begin{bmatrix}\n",
        " x\\\\ \n",
        " y\\\\\n",
        " \\end{bmatrix}$\n",
        "\n",
        "$ Î£=\n",
        "\\begin{bmatrix}\n",
        " 6 & 4\\\\ \n",
        " 4 & 5\\\\\n",
        " \\end{bmatrix}\\begin{bmatrix}\n",
        " x\\\\ \n",
        " y\\\\\n",
        " \\end{bmatrix}=9.5\\begin{bmatrix}\n",
        " x\\\\ \n",
        " y\\\\\n",
        " \\end{bmatrix}$\n",
        "\n",
        " $6x+4y=9.5x$\n",
        "\n",
        " $4x+5y=9.5y$\n",
        "\n",
        "on simplifying\n",
        "\n",
        "$-3.5x+4y=0$\n",
        " \n",
        " $4x-4.5y=0$ \n",
        "\n",
        " on simplifying\n",
        "\n",
        " $0.5x-0.5y=0 \\,\\therefore x=y$\n",
        "\n",
        "let x=1 then y=1 we get eigen vector $w_1=\\begin{bmatrix}\n",
        " 1\\\\ \n",
        " 1\\\\\n",
        " \\end{bmatrix}$\n",
        "\n",
        " similarly for $\\lambda_2=1.5,\\,$ we get eigen vector $w_2=\\begin{bmatrix}\n",
        " -1\\\\ \n",
        " 1\\\\\n",
        " \\end{bmatrix}$\n",
        "\n",
        " we can get projection of given input=A by using $(A.w_1),\\,$ along direction of maximum variance and $(A.w_2),\\,$ perpendicular to maximum variance \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R0b8VlwqQN2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.Calculate Projections,W=unit vectors along variance(Eigen vectors) and Diagonal variances(Eigen values)"
      ],
      "metadata": {
        "id": "enDwzHqvw136"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import mean\n",
        "from numpy import cov\n",
        "from numpy.linalg import eig\n",
        "# define a matrix\n",
        "A = array([[1, 2], [3, 4], [5, 6]])\n",
        "print(\"given Input A\\n\")\n",
        "print(A)\n",
        "# calculate the mean of each column\n",
        "M = mean(A.T, axis=1)\n",
        "print(\"\\n Mean of each column \\n\")\n",
        "\n",
        "print(M)\n",
        "# center columns by subtracting column means\n",
        "C = A - M\n",
        "print(\"\\n C=normalised array elements(substract mean fronm each element of Array) \\n\")\n",
        "\n",
        "print(C)\n",
        "# calculate covariance matrix of centered matrix\n",
        "V = cov(C.T)\n",
        "print(\"\\n covariance matrix V \\n\")\n",
        "\n",
        "print(V)\n",
        "# eigendecomposition of covariance matrix\n",
        "values, vectors = eig(V)\n",
        "print(\"\\n w=Eigen Vectors(unit vectors along variance)\\n\")\n",
        "\n",
        "print(vectors)\n",
        "print(\"\\n variance=Eigen Values \\n\")\n",
        "print(values)\n",
        "# project data\n",
        "P = C.dot(vectors)\n",
        "print(\"\\n projection of Input C.w\\n\")\n",
        "print(P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--u9K8c7e17V",
        "outputId": "bddddc50-4066-4ab2-dbbe-8eeae61a91ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "given Input A\n",
            "\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "\n",
            " Mean of each column \n",
            "\n",
            "[3. 4.]\n",
            "\n",
            " C=normalised array elements(substract mean fronm each element of Array) \n",
            "\n",
            "[[-2. -2.]\n",
            " [ 0.  0.]\n",
            " [ 2.  2.]]\n",
            "\n",
            " covariance matrix V \n",
            "\n",
            "[[4. 4.]\n",
            " [4. 4.]]\n",
            "\n",
            " w=Eigen Vectors(unit vectors along variance)\n",
            "\n",
            "[[ 0.70710678 -0.70710678]\n",
            " [ 0.70710678  0.70710678]]\n",
            "\n",
            " variance=Eigen Values \n",
            "\n",
            "[8. 0.]\n",
            "\n",
            " projection of Input C.w\n",
            "\n",
            "[[-2.82842712  0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 2.82842712  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Using SKLEARN:Calculate Projections,W=unit vectors along variance(Eigen vectors) and Diagonal variances(Eigen values)"
      ],
      "metadata": {
        "id": "Wm91H5T6xVJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Principal Component Analysis\n",
        "from numpy import array\n",
        "from sklearn.decomposition import PCA\n",
        "# define a matrix\n",
        "A = array([[1, 2], [3, 4], [5, 6]])\n",
        "print(\"given Input A\\n\")\n",
        "\n",
        "print(A)\n",
        "# create the PCA instance\n",
        "pca = PCA(2)\n",
        "# fit on data\n",
        "pca.fit(A)\n",
        "# access values and vectors\n",
        "print(\"\\n PCA components A\\n\")\n",
        "\n",
        "print(pca.components_)\n",
        "print(\"\\n PCA variance A\\n\")\n",
        "\n",
        "print(pca.explained_variance_)\n",
        "# transform data\n",
        "B = pca.transform(A)\n",
        "print(\"\\n projection of  A\\n\")\n",
        "\n",
        "print(B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCsbDNkqmHY5",
        "outputId": "0556755e-cb1e-4a01-e9da-9d8617035dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "given Input A\n",
            "\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "\n",
            " PCA components A\n",
            "\n",
            "[[ 0.70710678  0.70710678]\n",
            " [-0.70710678  0.70710678]]\n",
            "\n",
            " PCA variance A\n",
            "\n",
            "[8. 0.]\n",
            "\n",
            " projection of  A\n",
            "\n",
            "[[-2.82842712e+00 -2.22044605e-16]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 2.82842712e+00  2.22044605e-16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.Function to Calculate Projections,W=unit vectors along variance(Eigen vectors) and Diagonal variances(Eigen values)"
      ],
      "metadata": {
        "id": "Kl1OjpDIxgij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import mean\n",
        "from numpy import cov\n",
        "from numpy.linalg import eig\n",
        "def Calc_PCA(A):\n",
        "    # define a matrix\n",
        "    #A = array([[1, 2], [3, 4], [5, 6]])\n",
        "    print(\"given Input A\\n\")\n",
        "    print(A)\n",
        "    # calculate the mean of each column\n",
        "    M = mean(A.T, axis=1)\n",
        "    print(\"\\n Mean of each column \\n\")\n",
        "    print(M)\n",
        "    # center columns by subtracting column means\n",
        "    C = A - M\n",
        "    print(\"\\n C=normalised array elements(substract mean fronm each element of Array) \\n\")\n",
        "    print(C)\n",
        "    # calculate covariance matrix of centered matrix\n",
        "    V = cov(C.T)\n",
        "    print(\"\\n covariance matrix V \\n\")\n",
        "    print(V)\n",
        "    # eigendecomposition of covariance matrix\n",
        "    values, vectors = eig(V)\n",
        "    print(\"\\n w=Eigen Vectors(unit vectors along variance) \\n\")\n",
        "    print(vectors)\n",
        "    print(\"\\n variance=Eigen Values \\n\")\n",
        "    print(values)\n",
        "    # project data\n",
        "    P = C.dot(vectors)\n",
        "    print(\"\\n projection of Input C.w\\n\")\n",
        "    print(P)"
      ],
      "metadata": {
        "id": "GEIYjUoyj7mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.calculate PCA "
      ],
      "metadata": {
        "id": "YcOUujo96BJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = array([[1, 2,3], [4, 5,6], [7, 8,9]])\n",
        "Calc_PCA(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stkecafblSW9",
        "outputId": "c36650c5-1b4f-4d4f-984d-facbf22c1fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "given Input A\n",
            "\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            " Mean of each column \n",
            "\n",
            "[4. 5. 6.]\n",
            "\n",
            " C=normalised array elements(substract mean fronm each element of Array) \n",
            "\n",
            "[[-3. -3. -3.]\n",
            " [ 0.  0.  0.]\n",
            " [ 3.  3.  3.]]\n",
            "\n",
            " covariance matrix V \n",
            "\n",
            "[[9. 9. 9.]\n",
            " [9. 9. 9.]\n",
            " [9. 9. 9.]]\n",
            "\n",
            " w=Eigen Vectors(unit vectors along variance) \n",
            "\n",
            "[[-0.81649658  0.57735027  0.        ]\n",
            " [ 0.40824829  0.57735027 -0.70710678]\n",
            " [ 0.40824829  0.57735027  0.70710678]]\n",
            "\n",
            " variance=Eigen Values \n",
            "\n",
            "[ 0. 27.  0.]\n",
            "\n",
            " projection of Input C.w\n",
            "\n",
            "[[ 1.11022302e-16 -5.19615242e+00  4.44089210e-16]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [-1.11022302e-16  5.19615242e+00 -4.44089210e-16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13 Spectral decomposition of S(S=Estimate of  Covariance matrix)\n",
        "\n",
        "### Estimate Covariance from Eigen values and Eigen vectors\n",
        "\n",
        "Let S be estimate of Covariance matrix of given data\n",
        "\n",
        "C=unit vector along maximum variance(Eigen Vectors)\n",
        "\n",
        "$\\lambda$ = variances(Eigen values)\n",
        "\n",
        "$ \\therefore S=C (\\lambda I )C^T$\n",
        "\n",
        "we can write as\n",
        "\n",
        "$S=C DC^T$\n",
        "\n",
        "where D=diagonal matrix having eigen values\n",
        "\n",
        "***Proof***\n",
        "$S = SCC^T$ because $CC^T=1$\n",
        "\n",
        "$S= S(c_1, c_2, . . . , c_d)C^T$\n",
        "\n",
        "$S= (Sc_1, Sc_2, . . . , Sc_d)C^T$\n",
        "\n",
        "$S= (Î»_1c_1, Î»_2c_2, . . . , Î»_dc_d)C^T$\n",
        "\n",
        "$S= Î»_1c_1c^T_1+Â· Â· Â·+Î»_dc_dc^T_d$\n",
        "\n",
        " $S= CDC^T$\n",
        "\n"
      ],
      "metadata": {
        "id": "GFh3ebHI0p9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import multi_dot\n",
        "\n",
        "A = array([[1, 12,30], [8, 5,21], [7, 4,9]])\n",
        "M = mean(A.T, axis=1)\n",
        "print(\"\\n Mean of each column \\n\")\n",
        "print(M)\n",
        "# center columns by subtracting column means\n",
        "C = A - M\n",
        "print(\"\\n C=normalised array elements(substract mean fronm each element of Array) \\n\")\n",
        "print(C)\n",
        "# calculate covariance matrix of centered matrix\n",
        "V = cov(C.T)\n",
        "Eigenvalues, Eigenvectors = eig(V)\n",
        "print(\"\\n Eigen Values \\n\",Eigenvalues)\n",
        "print(\"\\n Eigen Vectors \\n\",Eigenvectors)\n",
        "Ei_val_sort=np.sort(Eigenvalues)[::-1]\n",
        "\n",
        "print(\"\\n Ei_val_sort \\n\",Ei_val_sort)\n",
        "I = np.identity(3)\n",
        "D = np.diag(Eigenvalues)\n",
        "S = np.linalg.multi_dot([Eigenvectors, D, Eigenvectors.T])\n",
        "\n",
        "print(\"\\n Diagonal Matrix of eigen values(variances) D \\n\",D)\n",
        "\n",
        "print(\"\\n Estimated Covariance MatrixS \\n\",S)\n",
        "\n",
        "print(\"\\n covariance matrix V \\n\")\n",
        "print(V)\n"
      ],
      "metadata": {
        "id": "q_Iug3vWhdvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70f550d2-c523-4331-d6ca-e3bbee5a2d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Mean of each column \n",
            "\n",
            "[ 5.33333333  7.         20.        ]\n",
            "\n",
            " C=normalised array elements(substract mean fronm each element of Array) \n",
            "\n",
            "[[ -4.33333333   5.          10.        ]\n",
            " [  2.66666667  -2.           1.        ]\n",
            " [  1.66666667  -3.         -11.        ]]\n",
            "\n",
            " Eigen Values \n",
            " [1.35429566e+02 8.90376724e+00 2.99085883e-15]\n",
            "\n",
            " Eigen Vectors \n",
            " [[-0.26508201  0.73552445 -0.62348642]\n",
            " [ 0.34908173 -0.52954936 -0.77312316]\n",
            " [ 0.89881782  0.42258876  0.11638413]]\n",
            "\n",
            " Ei_val_sort \n",
            " [1.35429566e+02 8.90376724e+00 2.99085883e-15]\n",
            "\n",
            " Diagonal Matrix of eigen values(variances) D \n",
            " [[1.35429566e+02 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 8.90376724e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 2.99085883e-15]]\n",
            "\n",
            " Estimated Covariance MatrixS \n",
            " [[ 14.33333333 -16.         -29.5       ]\n",
            " [-16.          19.          40.5       ]\n",
            " [-29.5         40.5        111.        ]]\n",
            "\n",
            " covariance matrix V \n",
            "\n",
            "[[ 14.33333333 -16.         -29.5       ]\n",
            " [-16.          19.          40.5       ]\n",
            " [-29.5         40.5        111.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14 Q.What is proportion of variance?\n",
        "\n",
        "***PCA procedure:***\n",
        "\n",
        "1.Even if all eigenvalues are greater than 0,  we understand that some eigenvalues have little contribution to variance and may be discarded. \n",
        "\n",
        "because if $|S| \\,is \\,small\\ we \\ know  \\ that $$|S|=\\prod^d_{i=1} Î»_i$\n",
        "\n",
        "2.Then, we take into account the leading k components that explain more than, for example,90 percent, of the variance. When $Î»_i$ are sorted in descending order.\n",
        " \n",
        "3.The  proportion of variance explained by the k principal components is\n",
        "variance\n",
        "\n",
        "proportion of variance=$\\frac{ \\lambda_1+\\lambda_2+...+\\lambda_k }{\\lambda_1+\\lambda_2+...+\\lambda_k+...+\\lambda_d }$\n",
        "\n",
        "where d=number of dimensions\n",
        "      \n",
        "k=no of principal components\n",
        "\n",
        "***Uses***\n",
        "\n",
        "1.If the dimensions are ***highly correlated***, there will be a small number of\n",
        "eigenvectors with large eigenvalues and ***k will be much smaller than d*** and\n",
        "a large reduction in dimensionality may be attained. This is typically the\n",
        "case in many  ***image and speech processing tasks *** where nearby inputs (in\n",
        "space or time) are highly correlated. \n",
        "\n",
        "2.If the dimensions are ***not correlated, k will be as large as d ***and there is no gain through PCA."
      ],
      "metadata": {
        "id": "IJ1IxBBQ_7eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import sys\n",
        "#sys.getdefaultencoding()\n",
        "\n",
        "print(\"\\n covariance determinent |S| \\n\",np.linalg.det(V))\n",
        "Ei_prod=Eigenvalues[0]*Eigenvalues[1]*Eigenvalues[2]\n",
        "print(\"\\n product of eigen values \\u03BB \\n\",Ei_prod)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri2k0nbd0kwO",
        "outputId": "a2902c4b-0d13-4abf-9c3b-766cd588e320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " covariance determinent |S| \n",
            " 3.0837554731988364e-12\n",
            "\n",
            " product of eigen values Î» \n",
            " 3.6064772703132648e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15 SCREE GRAPH\n",
        "\n",
        "1.scree graph Scree graph is the plot of variance explained as a function of the number of eigenvectors (see figure below).\n",
        "\n",
        "2.By visually analyzing it, one can also decide on k=principal components. \n",
        "\n",
        "3.At the â€œelbow,â€in the following figure  adding another eigenvector does not\n",
        "significantly increase the variance explained."
      ],
      "metadata": {
        "id": "4ZgsmzOU7s56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "PC_components = [1,2,3]\n",
        "Eigensum=np.sum(Eigenvalues)\n",
        "Prop_variance=[(Eigenvalues[0]/Eigensum),((Eigenvalues[0]+Eigenvalues[1])/Eigensum),(Eigensum/Eigensum)]\n",
        "print(\"\\n Prop_variance \\n\",Prop_variance)\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
        "#fig.suptitle('Vertically stacked subplots')\n",
        "axs[0].plot(PC_components, Eigenvalues, 'o-', linewidth=2, color='blue')\n",
        "axs[1].plot(PC_components, Prop_variance, 'o-', linewidth=2, color='blue')\n",
        "#plt.plot(PC_components, Eigenvalues, 'o-', linewidth=2, color='blue')\n",
        "#plt.plot(PC_components, Prop_variance, 'o-', linewidth=2, color='blue')\n",
        "\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Variance Explained')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "PRJthW9-_5J1",
        "outputId": "1376f56c-00f5-4d0a-e43e-367259467be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Prop_variance \n",
            " [0.9383110815095959, 1.0, 1.0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 16 PCA selecting Eigen vectors Another approach:\n",
        "\n",
        "1. If the ***average of eigenvalues is equal to the average input variance***. \n",
        "\n",
        "2. we keep only the *** eigenvectors with eigenvalues greater than the average eigenvalue***, we keep only those that have variance higher than the average input variance."
      ],
      "metadata": {
        "id": "PUYGaFxBrsvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 17 Preprocessing  Inputs before PCA analysis\n",
        "\n",
        " 1. If the ***variances*** of the original $x_i$ dimensions vary considerably, they \n",
        "affect the direction of the principal components ***more than the correlations.***\n",
        "\n",
        " 2. so a common procedure is to preprocess the data so that each\n",
        "dimension has ***mean 0 and unit variance, before using PCA.*** \n",
        "\n",
        "3. Or, one may use the eigenvectors of the ***correlation matrix, R, instead of the covariance matrix, S,*** for the correlations to be effective and not the individual variances."
      ],
      "metadata": {
        "id": "l4NxHa8a9_Qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 18 PCA and Outliers\n",
        "\n",
        "1. PCA explains ***variance and is sensitive to outliers***. A few points distant from the center would have a large effect on the variances and thus the\n",
        "eigenvectors.\n",
        "\n",
        "2. ***Robust estimation*** methods allow calculating parameters in\n",
        "the presence of outliers. \n",
        "\n",
        "3. A simple method is to calculate the ***Mahalanobis distance of the data points***, discarding the isolated data points that are far away\n"
      ],
      "metadata": {
        "id": "gW1IVAAU-2NR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 19 PCA Visual analysis:\n",
        "\n",
        "1. If the ***first two principal components*** explain a large percentage of the\n",
        "variance, we can do visual analysis: We can ***plot the PCs*** in this two dimensional space (figure below) and search visually for ***structure, groups,\n",
        "outliers, normality, and so forth***. This plot gives a ***better pictorial description of the sample than a plot of any two of the original variables.***\n",
        "\n",
        "2. By looking at the dimensions of the principal components, we can also\n",
        "try to recover meaningful underlying variables that describe the data. For\n",
        "example, in image applications where the inputs are images, ***the eigenvectors\n",
        "can also be displayed as images*** and can be seen as templates for\n",
        "eigenfaces important features; they are typically named ***â€œeigenfaces,â€ â€œeigendigits,â€***"
      ],
      "metadata": {
        "id": "sJYFM9SP_8Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(np.random.randint(0,100,size=(15, 4)), columns=['X1','X2','X3','X4'])\n",
        "\n",
        "A = df.to_numpy()\n",
        "M = mean(A.T, axis=1)\n",
        "print(\"\\n Mean of each column \\n\")\n",
        "print(M)\n",
        "# center columns by subtracting column means\n",
        "C = A - M\n",
        "print(\"\\n C=normalised array elements(substract mean fronm each element of Array) \\n\")\n",
        "print(C)\n",
        "# calculate covariance matrix of centered matrix\n",
        "V = cov(C.T)\n",
        "Eigenvalues, Eigenvectors = eig(V)\n",
        "print(\"\\n Eigen Values \\n\",Eigenvalues)\n",
        "print(\"\\n Eigen Vectors \\n\",Eigenvectors)\n",
        "Ei_val_sort=np.sort(Eigenvalues)[::-1]\n",
        "\n",
        "print(\"\\n Ei_val_sort \\n\",Ei_val_sort)\n",
        "I = np.identity(3)\n",
        "D = np.diag(Eigenvalues)\n",
        "S = np.linalg.multi_dot([Eigenvectors, D, Eigenvectors.T])\n",
        "\n",
        "print(\"\\n Diagonal Matrix of eigen values(variances) D \\n\",D)\n",
        "\n",
        "print(\"\\n Estimated Covariance MatrixS \\n\",S)\n",
        "\n",
        "print(\"\\n covariance matrix V \\n\")\n",
        "print(V)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aMoD3UJuG13",
        "outputId": "b273dc06-ae55-4cce-8ff2-3f5ca8a45328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Mean of each column \n",
            "\n",
            "[33.66666667 50.8        47.         50.46666667]\n",
            "\n",
            " C=normalised array elements(substract mean fronm each element of Array) \n",
            "\n",
            "[[ -8.66666667   8.2         52.          44.53333333]\n",
            " [  1.33333333 -42.8         43.         -44.46666667]\n",
            " [-32.66666667   9.2        -38.          10.53333333]\n",
            " [  0.33333333 -34.8        -23.          31.53333333]\n",
            " [ 31.33333333 -30.8         12.         -23.46666667]\n",
            " [  5.33333333  16.2         19.         -11.46666667]\n",
            " [ -5.66666667   9.2         -6.         -32.46666667]\n",
            " [ 43.33333333  17.2        -14.         -31.46666667]\n",
            " [-18.66666667   8.2        -12.          17.53333333]\n",
            " [ 12.33333333  13.2         47.         -14.46666667]\n",
            " [  2.33333333 -16.8        -45.          48.53333333]\n",
            " [-27.66666667  20.2        -44.           8.53333333]\n",
            " [ -3.66666667  17.2         33.         -43.46666667]\n",
            " [  7.33333333  10.2        -39.          40.53333333]\n",
            " [ -6.66666667  -3.8         15.          -0.46666667]]\n",
            "\n",
            " Eigen Values \n",
            " [1658.92035192  282.28578063  602.57379977  474.89625815]\n",
            "\n",
            " Eigen Vectors \n",
            " [[ 0.19840718 -0.83906484 -0.15813776  0.48124551]\n",
            " [-0.04678007 -0.47359028 -0.17118259 -0.86268209]\n",
            " [ 0.73652298 -0.03633404  0.65842252 -0.15064369]\n",
            " [-0.6449652  -0.2652589   0.71565967  0.03858557]]\n",
            "\n",
            " Ei_val_sort \n",
            " [1658.92035192  602.57379977  474.89625815  282.28578063]\n",
            "\n",
            " Diagonal Matrix of eigen values(variances) D \n",
            " [[1658.92035192    0.            0.            0.        ]\n",
            " [   0.          282.28578063    0.            0.        ]\n",
            " [   0.            0.          602.57379977    0.        ]\n",
            " [   0.            0.            0.          474.89625815]]\n",
            "\n",
            " Estimated Covariance MatrixS \n",
            " [[ 389.0952381   -84.07142857  153.85714286 -208.83333333]\n",
            " [ -84.07142857  438.02857143  -58.5          -4.11428571]\n",
            " [ 153.85714286  -58.5        1172.28571429 -504.14285714]\n",
            " [-208.83333333   -4.11428571 -504.14285714 1019.26666667]]\n",
            "\n",
            " covariance matrix V \n",
            "\n",
            "[[ 389.0952381   -84.07142857  153.85714286 -208.83333333]\n",
            " [ -84.07142857  438.02857143  -58.5          -4.11428571]\n",
            " [ 153.85714286  -58.5        1172.28571429 -504.14285714]\n",
            " [-208.83333333   -4.11428571 -504.14285714 1019.26666667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 20 Visually identify groups, outliers,norms from  original data plot and PCA plots from following figure\n",
        "\n"
      ],
      "metadata": {
        "id": "PXD5tn7R4djJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "n = range(1,15+1)\n",
        "\n",
        "x=A[:,0]\n",
        "y=A[:,2]\n",
        "#plt.figure(figsize=(12, 12))\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(12,6))\n",
        "\n",
        "ax1.scatter(x,y)\n",
        "ax1.set_xlabel(\"X1\")\n",
        "ax1.set_ylabel(\"X3\")\n",
        "\n",
        "for i, txt in enumerate(n):\n",
        "    ax1.annotate(txt, (x[i], y[i]))\n",
        "\n",
        "P=A@Eigenvectors\n",
        "\n",
        "x=P[:,0]\n",
        "y=P[:,2]\n",
        "ax2.scatter(x,y)\n",
        "ax2.set_xlabel(\"PC1\")\n",
        "ax2.set_ylabel(\"PC3\")\n",
        "for i, txt in enumerate(n):\n",
        "    ax2.annotate(txt, (x[i], y[i]))\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "ogxXfGnStBFY",
        "outputId": "baf651dc-703c-43f2-d589-1389f5b13ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 21 why PCA is easy  for Classification? \n",
        "\n",
        "1. We know  that if $X âˆ¼N_d(Î¼,Î£)$, \n",
        "2. then after projection $W^T x âˆ¼N_k(W^TÎ¼,W^TÎ£W)$. \n",
        "3. If the sample contains d-variate normals, then\n",
        "it projects to k-variate normals allowing us to do parametric discrimination\n",
        "in this lower-dimensional space.\n",
        "\n",
        "4.  Because projections $z_j$ are uncorrelated, the new covariance matrices will be diagonal, and if they are normalized to have unit variance, Euclidean distance can be used in this new space, leading to a simple classifier."
      ],
      "metadata": {
        "id": "Iv9-n3JL58cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 22 Reconstruction Error\n",
        "\n",
        "we know projection as follows from PCA:\n",
        "\n",
        "$z^t = W^T (x^t âˆ’ Î¼)$\n",
        "\n",
        "From above equation we can back project X (reconstruct X)as follows \n",
        "\n",
        "\n",
        "$ {\\hat x}^t = Wz^t + Î¼$\n",
        "\n",
        "Reconstruction Error is:\n",
        "\n",
        "$ \\Sigma_t ||x^t-{\\hat x}^t||^2$\n",
        "\n",
        "1. for ***PCA*** dimensionality reduction we ***discard some eigenvectors*** with nonzero eigenvalues.\n",
        "2. there will be a ***reconstruction error*** and its magnitude will ***depend on the discarded eigenvalues***. \n",
        "3. In a visual recognition applicationâ€”for example, ***face recognition***â€”displaying ${\\hat x}^t$allows a visual check for information loss during PCA\n"
      ],
      "metadata": {
        "id": "mWkSA0SU6zIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  23 Karhunen-LoÃ¨ve expansion  for Classification\n",
        "\n",
        "1. PCA is unsupervised and does not use output information. It is a onegroup\n",
        "procedure. However, ***in the case of classification, there are multiple\n",
        " groups.***\n",
        "\n",
        "2.  Karhunen-LoÃ¨ve expansion allows using class information\n",
        "\n",
        "3. for example, instead of using the covariance matrix of the whole sample, we can estimate ***separate class covariance matrices, take their average (weighted\n",
        "by the priors) as the covariance matrix, and use its eigenvectors.***"
      ],
      "metadata": {
        "id": "FqW5Gb97-iaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 24 Common principal components for Classification\n",
        "\n",
        " 1. we assume that the ***principal components  are the same for each class*** whereas the ***variances of these components differ for different classes:***\n",
        "\n",
        "$S_i = CD_iC^T$\n",
        "\n",
        "2. This allows pooling data and is a ***regularization method*** whose complexity is less than that of a common covariance matrix for all classes ***flexible while still allowing differentiation of $S_i$.***"
      ],
      "metadata": {
        "id": "tbR9Clpw_uC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 25 Flexible discriminant analysis\n",
        "1. It is  discriminant analysis (Hastie, Tibshirani, and Buja 1994), which does a ***linear projection to a lower-dimensional space*** where all **features** are **uncorrelated** and then uses a **minimum distance classifier.**"
      ],
      "metadata": {
        "id": "wSM9HL3EBG6t"
      }
    }
  ]
}