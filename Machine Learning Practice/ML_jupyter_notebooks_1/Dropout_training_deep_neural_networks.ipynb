{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpcfeYjEgejY"
      },
      "source": [
        "**Training Deep Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AyAcV11gejp"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6J0mDqTgejr"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ftwq9dUrgejt"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A04SAPzsgej1"
      },
      "source": [
        "# Vanishing/Exploding Gradients Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGTn8PyNgekG"
      },
      "source": [
        "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ess7RWligekG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e9c331-a1d1-4619-d708-d7231a46ccf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r70rveU2gekZ"
      },
      "source": [
        "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMEp-CUPgekZ"
      },
      "outputs": [],
      "source": [
        "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqiqlde0gelg"
      },
      "source": [
        "# Avoiding Overfitting Through Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6op3Pprigelh"
      },
      "source": [
        "## $\\ell_1$ and $\\ell_2$ regularization\n",
        "\n",
        "https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261\n",
        "\n",
        "1. The l2() function returns a regularizer that will be called at each step during training to compute the regularization loss. This is then added to the final loss. \n",
        "\n",
        "2. As you might expect, you can just use keras.regularizers.l1() if you want ℓ1 regularization; \n",
        "\n",
        "3. if you want both ℓ1 and ℓ2 regularization, use keras.regularizers.l1_l2() (specifying both regularization factors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekH-Pqjjgelh"
      },
      "outputs": [],
      "source": [
        "layer = keras.layers.Dense(100, activation=\"elu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
        "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHb7fU0hgelh",
        "outputId": "6d571e53-a1d5-4497-af3d-95e1d191beff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/2\n",
            "55000/55000 [==============================] - 7s 130us/sample - loss: 1.5735 - accuracy: 0.8126 - val_loss: 0.7327 - val_accuracy: 0.8222\n",
            "Epoch 2/2\n",
            "55000/55000 [==============================] - 6s 115us/sample - loss: 0.7186 - accuracy: 0.8260 - val_loss: 0.6929 - val_accuracy: 0.8338\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(100, activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(10, activation=\"softmax\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can  use Python’s functools.partial() function,\n",
        "which lets you create a thin wrapper for any callable, with some default argument values as shown below"
      ],
      "metadata": {
        "id": "q_Q3lCFdDFAX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at-oZ45Zgeli",
        "outputId": "0fb2eabf-09d7-48ef-871f-bc03ef7e4ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/2\n",
            "55000/55000 [==============================] - 7s 133us/sample - loss: 1.6006 - accuracy: 0.8129 - val_loss: 0.7374 - val_accuracy: 0.8236\n",
            "Epoch 2/2\n",
            "55000/55000 [==============================] - 7s 128us/sample - loss: 0.7179 - accuracy: 0.8265 - val_loss: 0.6905 - val_accuracy: 0.8356\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "RegularizedDense = partial(keras.layers.Dense,\n",
        "                           activation=\"elu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    RegularizedDense(300),\n",
        "    RegularizedDense(100),\n",
        "    RegularizedDense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hHs1VUEgeli"
      },
      "source": [
        "## Dropout\n",
        "\n",
        " With dropout regularization, at each ***training iteration a random subset of\n",
        "all neurons in one or more layers—except the output layer—are “dropped out”; these neurons output 0 at this iteration ***\n",
        "\n",
        " Suppose drop out rate is p = 50%, in which case during testing, a neuron would be connected to twice as many input neurons as it would be (on average) during training.\n",
        "\n",
        " To compensate for this fact, we need to multiply each neuron’s input ***connection weights by 0.5 after training.***  If we don’t, each\n",
        "neuron will get a total input signal roughly twice as large as what the network was trained on and will be unlikely to perform well. \n",
        "\n",
        "More generally, we need to ***multiply each input connection weight by the keep probability (1 – p) after training.***\n",
        "\n",
        " Alternatively, we can*** divide each neuron’s output by the keep probability during training*** (these alternatives are not perfectly equivalent, but they work equally well)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvKL3Bh0gelj",
        "outputId": "7262354b-6bb3-4483-d2b7-e893a344c864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.5708 - accuracy: 0.8056 - val_loss: 0.3886 - val_accuracy: 0.8580\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4222 - accuracy: 0.8451 - val_loss: 0.3391 - val_accuracy: 0.8716\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln-UZjSmgelj"
      },
      "source": [
        "## Alpha Dropout\n",
        "\n",
        "Applies Alpha Dropout to the input.\n",
        "\n",
        " Alpha Dropout is a Dropout that ***keeps mean and variance of inputs to their original values, in order to ensure the self-normalizing property even after this dropout.***\n",
        " \n",
        "  Alpha Dropout fits well to Scaled Exponential Linear Units by randomly setting activations to the negative saturation value. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Idh6DXGgelk"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPYIskIBgelk",
        "outputId": "36818eb7-ebf7-41bc-d775-13a5b4b7e35b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "55000/55000 [==============================] - 3s 55us/sample - loss: 0.6616 - accuracy: 0.7616 - val_loss: 0.6682 - val_accuracy: 0.8258\n",
            "Epoch 2/20\n",
            "55000/55000 [==============================] - 3s 49us/sample - loss: 0.5526 - accuracy: 0.7969 - val_loss: 0.5835 - val_accuracy: 0.8382\n",
            "Epoch 3/20\n",
            "55000/55000 [==============================] - 3s 48us/sample - loss: 0.5259 - accuracy: 0.8060 - val_loss: 0.5312 - val_accuracy: 0.8512\n",
            "Epoch 4/20\n",
            "55000/55000 [==============================] - 3s 49us/sample - loss: 0.5076 - accuracy: 0.8111 - val_loss: 0.4969 - val_accuracy: 0.8606\n",
            "Epoch 5/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4929 - accuracy: 0.8175 - val_loss: 0.4875 - val_accuracy: 0.8610\n",
            "Epoch 6/20\n",
            "55000/55000 [==============================] - 3s 48us/sample - loss: 0.4844 - accuracy: 0.8190 - val_loss: 0.5141 - val_accuracy: 0.8552\n",
            "Epoch 7/20\n",
            "55000/55000 [==============================] - 3s 48us/sample - loss: 0.4716 - accuracy: 0.8258 - val_loss: 0.4474 - val_accuracy: 0.8660\n",
            "Epoch 8/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4643 - accuracy: 0.8272 - val_loss: 0.4535 - val_accuracy: 0.8596\n",
            "Epoch 9/20\n",
            "55000/55000 [==============================] - 3s 48us/sample - loss: 0.4574 - accuracy: 0.8302 - val_loss: 0.4602 - val_accuracy: 0.8652\n",
            "Epoch 10/20\n",
            "55000/55000 [==============================] - 3s 48us/sample - loss: 0.4500 - accuracy: 0.8345 - val_loss: 0.4225 - val_accuracy: 0.8652\n",
            "Epoch 11/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4484 - accuracy: 0.8334 - val_loss: 0.4461 - val_accuracy: 0.8674\n",
            "Epoch 12/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4466 - accuracy: 0.8341 - val_loss: 0.4461 - val_accuracy: 0.8688\n",
            "Epoch 13/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4402 - accuracy: 0.8377 - val_loss: 0.4570 - val_accuracy: 0.8730\n",
            "Epoch 14/20\n",
            "55000/55000 [==============================] - 3s 48us/sample - loss: 0.4336 - accuracy: 0.8390 - val_loss: 0.4867 - val_accuracy: 0.8708\n",
            "Epoch 15/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4324 - accuracy: 0.8404 - val_loss: 0.4342 - val_accuracy: 0.8752\n",
            "Epoch 16/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4292 - accuracy: 0.8395 - val_loss: 0.4934 - val_accuracy: 0.8602\n",
            "Epoch 17/20\n",
            "55000/55000 [==============================] - 3s 49us/sample - loss: 0.4294 - accuracy: 0.8390 - val_loss: 0.4297 - val_accuracy: 0.8802\n",
            "Epoch 18/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4230 - accuracy: 0.8435 - val_loss: 0.4425 - val_accuracy: 0.8754\n",
            "Epoch 19/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4242 - accuracy: 0.8425 - val_loss: 0.4083 - val_accuracy: 0.8742\n",
            "Epoch 20/20\n",
            "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4201 - accuracy: 0.8450 - val_loss: 0.4256 - val_accuracy: 0.8766\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 20\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj1LFo8Tgell",
        "outputId": "5db47a10-2cdc-4c41-c230-f627bb81e34b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 25us/sample - loss: 0.4736 - accuracy: 0.8648\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.47358015085458754, 0.8648]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmx09hyQgell",
        "outputId": "68c231da-7899-4610-cfd3-8add76bd0db6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55000/55000 [==============================] - 1s 22us/sample - loss: 0.3532 - accuracy: 0.8859\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.35321958436965945, 0.8859091]"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAoCpv-xgell",
        "outputId": "5910c7d3-cbc0-42cb-a761-f892792f4bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 55000 samples\n",
            "55000/55000 [==============================] - 2s 44us/sample - loss: 0.4186 - accuracy: 0.8451\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTUcMXlggelm"
      },
      "source": [
        "## MC Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3r1qSqNgelm"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## syntax for prediction for keras model\n",
        "\n",
        "for small inputs prediction the syntax\n",
        "\n",
        "```model(X_test_scaled, training=True)```"
      ],
      "metadata": {
        "id": "hK8CC-XJ-yyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just make 100 predictions over the test set, setting training=True to ensure that the Dropout layer is active, and stack the predictions.\n",
        "\n",
        " Since dropout is active, all the\n",
        "predictions will be different. Recall that predict() returns a matrix with one row per instance and one column per class. Because there are 10,000 instances in the test set\n",
        "and 10 classes, this is a matrix of shape [10000, 10]. We stack 100 such matrices, so\n",
        "y_probas is an array of shape [100, 10000, 10]. Once we average over the first\n",
        "dimension (axis=0), we get y_proba, an array of shape [10000, 10], like we would get\n",
        "with a single prediction. That’s all! Averaging over multiple predictions with dropout\n",
        "on gives us a Monte Carlo estimate that is generally more reliable than the result of a\n",
        "single prediction with dropout off."
      ],
      "metadata": {
        "id": "t6t4I_Qh_vNF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59zMEeYPgelm"
      },
      "outputs": [],
      "source": [
        "y_probas = np.stack([model(X_test_scaled, training=True)\n",
        "                     for sample in range(100)])\n",
        "y_proba = y_probas.mean(axis=0)\n",
        "y_std = y_probas.std(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " For example, let’s look at the model’s prediction\n",
        "for the first instance in the Fashion MNIST test set, with dropout off:"
      ],
      "metadata": {
        "id": "t2lwn0ltAY77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jf_YQq5geln",
        "outputId": "0772942b-95fc-4601-cb12-99707a4e3d8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.29, 0.  , 0.61]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.round(model.predict(X_test_scaled[:1]), 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model seems almost certain that this image belongs to class 9 (ankle boot).\n",
        "Should you trust it? Is there really so little room for doubt? Compare this with the\n",
        "predictions made when dropout is activated:"
      ],
      "metadata": {
        "id": "NYn66McYAmPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__dJngbDgeln",
        "outputId": "0931e780-1997-4811-e887-d8e03d6f046d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.58, 0.  , 0.13]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.22, 0.  , 0.75]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.16, 0.  , 0.72]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.16, 0.  , 0.78]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.13, 0.  , 0.77]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.65, 0.  , 0.25]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.16, 0.  , 0.82]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.33, 0.  , 0.42]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.28, 0.  , 0.64]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.16, 0.  , 0.76]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.75, 0.  , 0.14]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.51, 0.  , 0.16]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.48, 0.  , 0.38]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.03, 0.  , 0.95]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.09, 0.  , 0.8 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.16, 0.  , 0.82]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.85, 0.  , 0.02, 0.  , 0.13]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.26, 0.  , 0.63]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.28, 0.  , 0.52]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.37, 0.  , 0.13, 0.  , 0.5 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.1 , 0.  , 0.75]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.31, 0.01, 0.56]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.52, 0.  , 0.09, 0.  , 0.38]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.62, 0.  , 0.15, 0.  , 0.23]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.18, 0.  , 0.78]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.04, 0.  , 0.91]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.6 , 0.  , 0.36]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.47, 0.  , 0.2 , 0.  , 0.33]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.4 , 0.  , 0.5 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.61, 0.02, 0.32]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.43, 0.04, 0.35]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.44, 0.  , 0.19, 0.  , 0.37]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.57, 0.  , 0.39]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.29, 0.  , 0.7 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.73, 0.  , 0.24]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.12, 0.  , 0.61]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.21, 0.  , 0.55]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.61, 0.  , 0.33]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.96]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.58, 0.  , 0.25]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.2 , 0.  , 0.78]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.92, 0.  , 0.08]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.1 , 0.  , 0.87]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.15, 0.  , 0.64]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.09, 0.  , 0.87]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.48, 0.  , 0.37]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.48, 0.  , 0.43]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.49, 0.  , 0.18, 0.  , 0.34]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.29, 0.  , 0.42]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.31, 0.  , 0.5 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.65, 0.01, 0.32]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.49, 0.  , 0.29, 0.01, 0.2 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.14, 0.  , 0.84]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.35, 0.  , 0.52]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.29, 0.  , 0.64]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.48, 0.  , 0.29, 0.  , 0.23]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.1 , 0.23, 0.34]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.48, 0.01, 0.28]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.12, 0.  , 0.86]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.11, 0.  , 0.86]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.04, 0.  , 0.92]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.3 , 0.  , 0.39]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.45, 0.  , 0.28, 0.  , 0.27]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.04, 0.  , 0.92]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.25, 0.  , 0.73]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.38, 0.  , 0.39, 0.  , 0.23]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.77, 0.  , 0.11, 0.  , 0.11]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.49, 0.  , 0.32, 0.  , 0.2 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.46, 0.  , 0.39]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.42, 0.  , 0.34]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.04, 0.  , 0.76]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.56, 0.  , 0.1 , 0.  , 0.34]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.04, 0.  , 0.69]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.93, 0.  , 0.04, 0.  , 0.03]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.31, 0.  , 0.67]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.88, 0.  , 0.1 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.17, 0.  , 0.42]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.23, 0.  , 0.5 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.76]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.24, 0.  , 0.59]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.29, 0.  , 0.59]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.45, 0.01, 0.3 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.06, 0.  , 0.9 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.18, 0.  , 0.8 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.27, 0.05, 0.52]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.27, 0.  , 0.67]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.09, 0.  , 0.56]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.23, 0.  , 0.64]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.45, 0.  , 0.22, 0.  , 0.34]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.21, 0.  , 0.72]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.66, 0.  , 0.3 ]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.18, 0.02, 0.56]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.21, 0.  , 0.64]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.04, 0.  , 0.77]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.14, 0.  , 0.81]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.02, 0.  , 0.94]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.58, 0.  , 0.19, 0.  , 0.23]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.5 , 0.  , 0.41]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.46, 0.  , 0.39, 0.03, 0.12]],\n",
              "\n",
              "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.11, 0.  , 0.61]]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.round(y_probas[:, :1], 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tells a very different story: apparently, when we activate dropout, the model is\n",
        "not sure anymore. It still seems to prefer class 9, but sometimes it hesitates with\n",
        "classes 5 (sandal) and 7 (sneaker), which makes sense given they’re all footwear. Once\n",
        "we average over the first dimension, we get the following MC Dropout predictions:"
      ],
      "metadata": {
        "id": "pgcMQCHrAtLs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSiCJqrigelo",
        "outputId": "a6618c1e-e9b3-4e9a-e1c9-73849c865bdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.28, 0.  , 0.52]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "np.round(y_proba[:1], 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model still thinks this image belongs to class 9, but only with a 62% confidence,\n",
        "which seems much more reasonable than 99%. Plus it’s useful to know exactly which\n",
        "other classes it thinks are likely. And you can also take a look at the standard deviation\n",
        "of the probability estimates:"
      ],
      "metadata": {
        "id": "ZIHb2bclA5eV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrlYGYaJgelo",
        "outputId": "acde727a-a8de-459f-aa88-e324dce9a456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.2 , 0.02, 0.25]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "y_std = y_probas.std(axis=0)\n",
        "np.round(y_std[:1], 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apparently there’s quite a lot of variance in the probability estimates: if you were\n",
        "building a risk-sensitive system (e.g., a medical or financial system), you should probably\n",
        "treat such an uncertain prediction with extreme caution. You definitely would\n",
        "not treat it like a 99% confident prediction. Moreover, the model’s accuracy got a\n",
        "small boost from 86.8 to 86.9:"
      ],
      "metadata": {
        "id": "_lQQ34XNBDdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmQs21q4gelp"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_proba, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iqRMIrIgelp",
        "outputId": "17d0f504-9ace-4f83-bdb0-5356e73e6e9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8593"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of Monte Carlo samples you use (100 in this example)\n",
        "is a hyperparameter you can tweak. The higher it is, the more accurate\n",
        "the predictions and their uncertainty estimates will be. However,\n",
        "if you double it, inference time will also be doubled.\n",
        "Moreover, above a certain number of samples, you will notice little\n",
        "improvement. So your job is to find the right trade-off between\n",
        "latency and accuracy, depending on your application."
      ],
      "metadata": {
        "id": "qYn0bvesBSDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your model contains other layers that behave in a special way during training (such\n",
        "as BatchNormalization layers), then you should not force training mode like we just\n",
        "did. Instead, you should replace the Dropout layers with the following MCDropout\n",
        "class:"
      ],
      "metadata": {
        "id": "m0k6ierkBe4F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84jO4thogelp"
      },
      "outputs": [],
      "source": [
        "class MCDropout(keras.layers.Dropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)\n",
        "\n",
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we just subclass the Dropout layer and override the call() method to force its\n",
        "training argument to True (see Chapter 12). Similarly, you could define an MCAlpha\n",
        "Dropout class by subclassing AlphaDropout instead. If you are creating a model from\n",
        "scratch, it’s just a matter of using MCDropout rather than Dropout. But if you have a\n",
        "model that was already trained using Dropout, you need to create a new model that’s\n",
        "identical to the existing model except that it replaces the Dropout layers with MCDrop\n",
        "out, then copy the existing model’s weights to your new model.\n",
        "In short, MC Dropout is a fantastic technique that boosts dropout models and provides\n",
        "better uncertainty estimates. And of course, since it is just regular dropout during\n",
        "training, it also acts like a regularizer."
      ],
      "metadata": {
        "id": "-nYfSNYwBmZJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCkvCVYBgelq"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLh5oN9_gelq"
      },
      "outputs": [],
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
        "    for layer in model.layers\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdlkvAhngelq",
        "outputId": "988afbc9-4d4d-4b7e-c724-9e186d5a95da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 300)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mc_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujltDQlzgelr"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuv8-Q6Fgelr"
      },
      "outputs": [],
      "source": [
        "mc_model.set_weights(model.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVIqTGk6gels"
      },
      "source": [
        "Now we can use the model with MC Dropout:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhKxgymSgels",
        "outputId": "ab4ebc88-14b1-4fa5-84f8-48550884b9d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.29, 0.  , 0.61]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV6LNFsNgelt"
      },
      "source": [
        "## Max norm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another regularization technique that is popular for neural networks is called maxnorm\n",
        "regularization: for each neuron, it constrains the weights w of the incoming\n",
        "connections such that ∥ w ∥2 ≤ r, where r is the max-norm hyperparameter and ∥ · ∥2\n",
        "is the ℓ2 norm.\n",
        "Max-norm regularization does not add a regularization loss term to the overall loss\n",
        "function. Instead, it is typically implemented by computing ∥w∥2 after each training\n",
        "step and rescaling w if needed (w ← w r/‖ w ‖2).\n",
        "\n",
        "Reducing r increases the amount of regularization and helps reduce overfitting. Maxnorm\n",
        "regularization can also help alleviate the unstable gradients problems (if you\n",
        "are not using Batch Normalization).\n",
        "To implement max-norm regularization in Keras, set the kernel_constraint argument\n",
        "of each hidden layer to a max_norm() constraint with the appropriate max value,\n",
        "like this:\n"
      ],
      "metadata": {
        "id": "FXzdsv-sBywp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zRrAaRHgelt"
      },
      "outputs": [],
      "source": [
        "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                           kernel_constraint=keras.constraints.max_norm(1.))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After each training iteration, the model’s fit() method will call the object returned\n",
        "by max_norm(), passing it the layer’s weights and getting rescaled weights in return,\n",
        "which then replace the layer’s weights. As you’ll see in Chapter 12, you can define\n",
        "your own custom constraint function if necessary and use it as the kernel_con\n",
        "straint. You can also constrain the bias terms by setting the bias_constraint\n",
        "argument.\n",
        "The max_norm() function has an axis argument that defaults to 0. A Dense layer usually\n",
        "has weights of shape [number of inputs, number of neurons], so using axis=0\n",
        "means that the max-norm constraint will apply independently to each neuron’s\n",
        "weight vector. If you want to use max-norm with convolutional layers (see Chapter\n",
        "14), make sure to set the max_norm() constraint’s axis argument appropriately\n",
        "(usually axis=[0, 1, 2])."
      ],
      "metadata": {
        "id": "iQEdBuZbCIcP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaS3tWoqgelt",
        "outputId": "f31ce6d8-a4dc-4e37-df8a-41f9ccaeec59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.4741 - accuracy: 0.8337 - val_loss: 0.3711 - val_accuracy: 0.8638\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3566 - accuracy: 0.8711 - val_loss: 0.3563 - val_accuracy: 0.8740\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "MaxNormDense = partial(keras.layers.Dense,\n",
        "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    MaxNormDense(300),\n",
        "    MaxNormDense(100),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "J-jQ_VwWgelu"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYitULAAgelu"
      },
      "source": [
        "## 1. to 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxEZbna5gelu"
      },
      "source": [
        "See appendix A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t93Bvp4-gelv"
      },
      "source": [
        "## 8. Deep Learning on CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKnzA-sugelv"
      },
      "source": [
        "### a.\n",
        "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QWG7siZgelv"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 activation=\"elu\",\n",
        "                                 kernel_initializer=\"he_normal\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90nJkbNNgelw"
      },
      "source": [
        "### b.\n",
        "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7evKJIsgelw"
      },
      "source": [
        "Let's add the output layer to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en4he-iygelx"
      },
      "outputs": [],
      "source": [
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gJbR6Atgelx"
      },
      "source": [
        "Let's use a Nadam optimizer with a learning rate of 5e-5. I tried learning rates 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3 and 1e-2, and I compared their learning curves for 10 epochs each (using the TensorBoard callback, below). The learning rates 3e-5 and 1e-4 were pretty good, so I tried 5e-5, which turned out to be slightly better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvsEGx0Fgely"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Nadam(lr=5e-5)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypVO4PGBgely"
      },
      "source": [
        "Let's load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let's use the first 5,000 images of the original training set as the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWFXp3Bbgelz"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train = X_train_full[5000:]\n",
        "y_train = y_train_full[5000:]\n",
        "X_valid = X_train_full[:5000]\n",
        "y_valid = y_train_full[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDPy0EKgel0"
      },
      "source": [
        "Now we can create the callbacks we need and train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqa49dubgel0"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tyi1bxggel1",
        "outputId": "a332a9b0-e36b-47dc-ec9c-d10a53387ccb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-71944bb8fa193bc4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-71944bb8fa193bc4\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          url.port = 6006;\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir=./my_cifar10_logs --port=6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9Qbg_5Mgel2",
        "outputId": "5e582cff-8340-4906-ff42-55f50c15f5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "45000/45000 [==============================] - 9s 208us/sample - loss: 4.0892 - accuracy: 0.1672 - val_loss: 2.1601 - val_accuracy: 0.2020\n",
            "Epoch 2/100\n",
            "45000/45000 [==============================] - 8s 175us/sample - loss: 2.0558 - accuracy: 0.2469 - val_loss: 1.9845 - val_accuracy: 0.2808\n",
            "Epoch 3/100\n",
            "45000/45000 [==============================] - 7s 161us/sample - loss: 1.9306 - accuracy: 0.2942 - val_loss: 1.9089 - val_accuracy: 0.2934\n",
            "Epoch 4/100\n",
            "45000/45000 [==============================] - 7s 157us/sample - loss: 1.8437 - accuracy: 0.3332 - val_loss: 1.7957 - val_accuracy: 0.3510\n",
            "Epoch 5/100\n",
            "45000/45000 [==============================] - 7s 162us/sample - loss: 1.7829 - accuracy: 0.3560 - val_loss: 1.7779 - val_accuracy: 0.3582\n",
            "Epoch 6/100\n",
            "45000/45000 [==============================] - 7s 154us/sample - loss: 1.7374 - accuracy: 0.3702 - val_loss: 1.8059 - val_accuracy: 0.3540\n",
            "Epoch 7/100\n",
            "45000/45000 [==============================] - 8s 171us/sample - loss: 1.6938 - accuracy: 0.3881 - val_loss: 1.7060 - val_accuracy: 0.3796\n",
            "Epoch 8/100\n",
            "45000/45000 [==============================] - 8s 174us/sample - loss: 1.6624 - accuracy: 0.4014 - val_loss: 1.7063 - val_accuracy: 0.3806\n",
            "Epoch 9/100\n",
            "45000/45000 [==============================] - 8s 180us/sample - loss: 1.6328 - accuracy: 0.4108 - val_loss: 1.6685 - val_accuracy: 0.4108\n",
            "Epoch 10/100\n",
            "45000/45000 [==============================] - 8s 176us/sample - loss: 1.6090 - accuracy: 0.4192 - val_loss: 1.6384 - val_accuracy: 0.4046\n",
            "Epoch 11/100\n",
            "45000/45000 [==============================] - 8s 172us/sample - loss: 1.5826 - accuracy: 0.4304 - val_loss: 1.6340 - val_accuracy: 0.4084\n",
            "Epoch 12/100\n",
            "45000/45000 [==============================] - 9s 194us/sample - loss: 1.5638 - accuracy: 0.4374 - val_loss: 1.6190 - val_accuracy: 0.4134\n",
            "Epoch 13/100\n",
            "45000/45000 [==============================] - 9s 197us/sample - loss: 1.5454 - accuracy: 0.4459 - val_loss: 1.5927 - val_accuracy: 0.4326\n",
            "Epoch 14/100\n",
            "45000/45000 [==============================] - 9s 196us/sample - loss: 1.5266 - accuracy: 0.4523 - val_loss: 1.6527 - val_accuracy: 0.4210\n",
            "Epoch 15/100\n",
            "45000/45000 [==============================] - 9s 203us/sample - loss: 1.5140 - accuracy: 0.4534 - val_loss: 1.5902 - val_accuracy: 0.4352\n",
            "Epoch 16/100\n",
            "45000/45000 [==============================] - 9s 196us/sample - loss: 1.4965 - accuracy: 0.4622 - val_loss: 1.6270 - val_accuracy: 0.4146\n",
            "Epoch 17/100\n",
            "45000/45000 [==============================] - 9s 199us/sample - loss: 1.4846 - accuracy: 0.4677 - val_loss: 1.6368 - val_accuracy: 0.4066\n",
            "<<49 more lines>>\n",
            "45000/45000 [==============================] - 10s 214us/sample - loss: 1.2420 - accuracy: 0.5531 - val_loss: 1.5280 - val_accuracy: 0.4594\n",
            "Epoch 43/100\n",
            "45000/45000 [==============================] - 10s 223us/sample - loss: 1.2347 - accuracy: 0.5564 - val_loss: 1.5307 - val_accuracy: 0.4692\n",
            "Epoch 44/100\n",
            "45000/45000 [==============================] - 10s 222us/sample - loss: 1.2271 - accuracy: 0.5579 - val_loss: 1.5747 - val_accuracy: 0.4626\n",
            "Epoch 45/100\n",
            "45000/45000 [==============================] - 10s 217us/sample - loss: 1.2224 - accuracy: 0.5587 - val_loss: 1.5249 - val_accuracy: 0.4678\n",
            "Epoch 46/100\n",
            "45000/45000 [==============================] - 10s 217us/sample - loss: 1.2108 - accuracy: 0.5636 - val_loss: 1.5235 - val_accuracy: 0.4786\n",
            "Epoch 47/100\n",
            "45000/45000 [==============================] - 10s 219us/sample - loss: 1.2049 - accuracy: 0.5655 - val_loss: 1.5776 - val_accuracy: 0.4594\n",
            "Epoch 48/100\n",
            "45000/45000 [==============================] - 10s 211us/sample - loss: 1.1984 - accuracy: 0.5687 - val_loss: 1.5269 - val_accuracy: 0.4690\n",
            "Epoch 49/100\n",
            "45000/45000 [==============================] - 10s 216us/sample - loss: 1.1893 - accuracy: 0.5736 - val_loss: 1.5449 - val_accuracy: 0.4682\n",
            "Epoch 50/100\n",
            "45000/45000 [==============================] - 10s 213us/sample - loss: 1.1850 - accuracy: 0.5741 - val_loss: 1.5345 - val_accuracy: 0.4800\n",
            "Epoch 51/100\n",
            "45000/45000 [==============================] - 9s 205us/sample - loss: 1.1772 - accuracy: 0.5749 - val_loss: 1.5430 - val_accuracy: 0.4660\n",
            "Epoch 52/100\n",
            "45000/45000 [==============================] - 10s 216us/sample - loss: 1.1701 - accuracy: 0.5777 - val_loss: 1.5470 - val_accuracy: 0.4684\n",
            "Epoch 53/100\n",
            "45000/45000 [==============================] - 10s 217us/sample - loss: 1.1628 - accuracy: 0.5802 - val_loss: 1.6219 - val_accuracy: 0.4622\n",
            "Epoch 54/100\n",
            "45000/45000 [==============================] - 10s 228us/sample - loss: 1.1582 - accuracy: 0.5820 - val_loss: 1.5455 - val_accuracy: 0.4778\n",
            "Epoch 55/100\n",
            "45000/45000 [==============================] - 10s 222us/sample - loss: 1.1499 - accuracy: 0.5866 - val_loss: 1.6274 - val_accuracy: 0.4534\n",
            "Epoch 56/100\n",
            "45000/45000 [==============================] - 10s 222us/sample - loss: 1.1451 - accuracy: 0.5893 - val_loss: 1.5577 - val_accuracy: 0.4736\n",
            "Epoch 57/100\n",
            "45000/45000 [==============================] - 10s 223us/sample - loss: 1.1406 - accuracy: 0.5903 - val_loss: 1.6167 - val_accuracy: 0.4610\n",
            "Epoch 58/100\n",
            "45000/45000 [==============================] - 10s 231us/sample - loss: 1.1372 - accuracy: 0.5896 - val_loss: 1.6059 - val_accuracy: 0.4564\n",
            "Epoch 59/100\n",
            "45000/45000 [==============================] - 10s 229us/sample - loss: 1.1271 - accuracy: 0.5938 - val_loss: 1.5618 - val_accuracy: 0.4660\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb37881c5c0>"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uND523fZgel2",
        "outputId": "a7db8ff6-cac2-4858-8890-8c2283b50c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 0s 65us/sample - loss: 1.5099 - accuracy: 0.4736\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.5099372177124024, 0.4736]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
        "model.evaluate(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02VFrTLmgel3"
      },
      "source": [
        "The model with the lowest validation loss gets about 47% accuracy on the validation set. It took 39 epochs to reach the lowest validation loss, with roughly 10 seconds per epoch on my laptop (without a GPU). Let's see if we can improve performance using Batch Normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qbfKNgYgel3"
      },
      "source": [
        "### c.\n",
        "*Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8AO5ug-gel3"
      },
      "source": [
        "The code below is very similar to the code above, with a few changes:\n",
        "\n",
        "* I added a BN layer after every Dense layer (before the activation function), except for the output layer. I also added a BN layer before the first hidden layer.\n",
        "* I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.\n",
        "* I renamed the run directories to run_bn_* and the model file name to my_cifar10_bn_model.h5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CCNnVSZgel3",
        "outputId": "95e15270-3722-49b5-eb3a-6cfce2ab5e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "45000/45000 [==============================] - 21s 466us/sample - loss: 1.8365 - accuracy: 0.3390 - val_loss: 1.6330 - val_accuracy: 0.4174\n",
            "Epoch 2/100\n",
            "45000/45000 [==============================] - 16s 352us/sample - loss: 1.6623 - accuracy: 0.4063 - val_loss: 1.5967 - val_accuracy: 0.4204\n",
            "Epoch 3/100\n",
            "45000/45000 [==============================] - 16s 355us/sample - loss: 1.5946 - accuracy: 0.4314 - val_loss: 1.5225 - val_accuracy: 0.4602\n",
            "Epoch 4/100\n",
            "45000/45000 [==============================] - 17s 367us/sample - loss: 1.5417 - accuracy: 0.4551 - val_loss: 1.4680 - val_accuracy: 0.4756\n",
            "Epoch 5/100\n",
            "45000/45000 [==============================] - 17s 367us/sample - loss: 1.5013 - accuracy: 0.4678 - val_loss: 1.4378 - val_accuracy: 0.4862\n",
            "Epoch 6/100\n",
            "45000/45000 [==============================] - 16s 361us/sample - loss: 1.4637 - accuracy: 0.4797 - val_loss: 1.4221 - val_accuracy: 0.4982\n",
            "Epoch 7/100\n",
            "45000/45000 [==============================] - 16s 355us/sample - loss: 1.4361 - accuracy: 0.4921 - val_loss: 1.4133 - val_accuracy: 0.4968\n",
            "Epoch 8/100\n",
            "45000/45000 [==============================] - 15s 326us/sample - loss: 1.4078 - accuracy: 0.4998 - val_loss: 1.3916 - val_accuracy: 0.5040\n",
            "Epoch 9/100\n",
            "45000/45000 [==============================] - 14s 315us/sample - loss: 1.3811 - accuracy: 0.5104 - val_loss: 1.3695 - val_accuracy: 0.5116\n",
            "Epoch 10/100\n",
            "45000/45000 [==============================] - 14s 318us/sample - loss: 1.3571 - accuracy: 0.5205 - val_loss: 1.3701 - val_accuracy: 0.5112\n",
            "Epoch 11/100\n",
            "45000/45000 [==============================] - 15s 329us/sample - loss: 1.3367 - accuracy: 0.5246 - val_loss: 1.3549 - val_accuracy: 0.5196\n",
            "Epoch 12/100\n",
            "45000/45000 [==============================] - 14s 316us/sample - loss: 1.3158 - accuracy: 0.5322 - val_loss: 1.4038 - val_accuracy: 0.5048\n",
            "Epoch 13/100\n",
            "45000/45000 [==============================] - 15s 328us/sample - loss: 1.3028 - accuracy: 0.5392 - val_loss: 1.3453 - val_accuracy: 0.5242\n",
            "Epoch 14/100\n",
            "45000/45000 [==============================] - 15s 331us/sample - loss: 1.2798 - accuracy: 0.5460 - val_loss: 1.3427 - val_accuracy: 0.5218\n",
            "Epoch 15/100\n",
            "45000/45000 [==============================] - 15s 327us/sample - loss: 1.2642 - accuracy: 0.5502 - val_loss: 1.3802 - val_accuracy: 0.5072\n",
            "Epoch 16/100\n",
            "45000/45000 [==============================] - 15s 336us/sample - loss: 1.2497 - accuracy: 0.5592 - val_loss: 1.3870 - val_accuracy: 0.5154\n",
            "Epoch 17/100\n",
            "45000/45000 [==============================] - 15s 332us/sample - loss: 1.2339 - accuracy: 0.5645 - val_loss: 1.3270 - val_accuracy: 0.5366\n",
            "Epoch 18/100\n",
            "45000/45000 [==============================] - 15s 331us/sample - loss: 1.2223 - accuracy: 0.5688 - val_loss: 1.3054 - val_accuracy: 0.5506\n",
            "Epoch 19/100\n",
            "45000/45000 [==============================] - 15s 339us/sample - loss: 1.2015 - accuracy: 0.5750 - val_loss: 1.3134 - val_accuracy: 0.5462\n",
            "Epoch 20/100\n",
            "45000/45000 [==============================] - 15s 326us/sample - loss: 1.1884 - accuracy: 0.5796 - val_loss: 1.3459 - val_accuracy: 0.5252\n",
            "Epoch 21/100\n",
            "45000/45000 [==============================] - 17s 370us/sample - loss: 1.1767 - accuracy: 0.5876 - val_loss: 1.3404 - val_accuracy: 0.5392\n",
            "Epoch 22/100\n",
            "45000/45000 [==============================] - 16s 366us/sample - loss: 1.1679 - accuracy: 0.5872 - val_loss: 1.3600 - val_accuracy: 0.5332\n",
            "Epoch 23/100\n",
            "45000/45000 [==============================] - 15s 337us/sample - loss: 1.1513 - accuracy: 0.5954 - val_loss: 1.3148 - val_accuracy: 0.5498\n",
            "Epoch 24/100\n",
            "45000/45000 [==============================] - 16s 346us/sample - loss: 1.1345 - accuracy: 0.6033 - val_loss: 1.3290 - val_accuracy: 0.5368\n",
            "Epoch 25/100\n",
            "45000/45000 [==============================] - 16s 350us/sample - loss: 1.1252 - accuracy: 0.6025 - val_loss: 1.3350 - val_accuracy: 0.5434\n",
            "Epoch 26/100\n",
            "45000/45000 [==============================] - 15s 341us/sample - loss: 1.1192 - accuracy: 0.6070 - val_loss: 1.3423 - val_accuracy: 0.5364\n",
            "Epoch 27/100\n",
            "45000/45000 [==============================] - 15s 342us/sample - loss: 1.1028 - accuracy: 0.6093 - val_loss: 1.3511 - val_accuracy: 0.5358\n",
            "Epoch 28/100\n",
            "45000/45000 [==============================] - 15s 332us/sample - loss: 1.0907 - accuracy: 0.6158 - val_loss: 1.3706 - val_accuracy: 0.5350\n",
            "Epoch 29/100\n",
            "45000/45000 [==============================] - 16s 345us/sample - loss: 1.0785 - accuracy: 0.6197 - val_loss: 1.3356 - val_accuracy: 0.5398\n",
            "Epoch 30/100\n",
            "45000/45000 [==============================] - 16s 352us/sample - loss: 1.0718 - accuracy: 0.6198 - val_loss: 1.3529 - val_accuracy: 0.5446\n",
            "Epoch 31/100\n",
            "45000/45000 [==============================] - 15s 333us/sample - loss: 1.0629 - accuracy: 0.6259 - val_loss: 1.3590 - val_accuracy: 0.5434\n",
            "Epoch 32/100\n",
            "45000/45000 [==============================] - 15s 331us/sample - loss: 1.0504 - accuracy: 0.6292 - val_loss: 1.3448 - val_accuracy: 0.5388\n",
            "Epoch 33/100\n",
            "45000/45000 [==============================] - 15s 325us/sample - loss: 1.0420 - accuracy: 0.6318 - val_loss: 1.3790 - val_accuracy: 0.5350\n",
            "Epoch 34/100\n",
            "45000/45000 [==============================] - 16s 346us/sample - loss: 1.0304 - accuracy: 0.6362 - val_loss: 1.3621 - val_accuracy: 0.5430\n",
            "Epoch 35/100\n",
            "45000/45000 [==============================] - 16s 356us/sample - loss: 1.0280 - accuracy: 0.6362 - val_loss: 1.3673 - val_accuracy: 0.5366\n",
            "Epoch 36/100\n",
            "45000/45000 [==============================] - 16s 354us/sample - loss: 1.0100 - accuracy: 0.6439 - val_loss: 1.3659 - val_accuracy: 0.5420\n",
            "Epoch 37/100\n",
            "45000/45000 [==============================] - 15s 329us/sample - loss: 1.0060 - accuracy: 0.6473 - val_loss: 1.3773 - val_accuracy: 0.5398\n",
            "Epoch 38/100\n",
            "45000/45000 [==============================] - 15s 332us/sample - loss: 0.9966 - accuracy: 0.6496 - val_loss: 1.3946 - val_accuracy: 0.5340\n",
            "5000/5000 [==============================] - 1s 157us/sample - loss: 1.3054 - accuracy: 0.5506\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.305354326057434, 0.5506]"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"elu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
        "model.evaluate(X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g9z4-NQgel4"
      },
      "source": [
        "* *Is the model converging faster than before?* Much faster! The previous model took 39 epochs to reach the lowest validation loss, while the new model with BN took 18 epochs. That's more than twice as fast as the previous model. The BN layers stabilized training and allowed us to use a much larger learning rate, so convergence was faster.\n",
        "* *Does BN produce a better model?* Yes! The final model is also much better, with 55% accuracy instead of 47%. It's still not a very good model, but at least it's much better than before (a Convolutional Neural Network would do much better, but that's a different topic, see chapter 14).\n",
        "* *How does BN affect training speed?* Although the model converged twice as fast, each epoch took about 16s instead of 10s, because of the extra computations required by the BN layers. So overall, although the number of epochs was reduced by 50%, the training time (wall time) was shortened by 30%. Which is still pretty significant!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd7-SCVygel4"
      },
      "source": [
        "### d.\n",
        "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "d6nT6T_6gel5",
        "outputId": "3082ae14-6804-43ce-d3fe-93105eec1088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "45000/45000 [==============================] - 12s 268us/sample - loss: 1.9310 - accuracy: 0.3055 - val_loss: 1.7814 - val_accuracy: 0.3566\n",
            "Epoch 2/100\n",
            "45000/45000 [==============================] - 10s 216us/sample - loss: 1.7077 - accuracy: 0.3935 - val_loss: 1.9245 - val_accuracy: 0.3654\n",
            "Epoch 3/100\n",
            "45000/45000 [==============================] - 10s 219us/sample - loss: 1.6116 - accuracy: 0.4314 - val_loss: 1.6612 - val_accuracy: 0.4316\n",
            "Epoch 4/100\n",
            "45000/45000 [==============================] - 10s 219us/sample - loss: 1.5385 - accuracy: 0.4590 - val_loss: 1.5879 - val_accuracy: 0.4414\n",
            "Epoch 5/100\n",
            "45000/45000 [==============================] - 11s 234us/sample - loss: 1.4911 - accuracy: 0.4746 - val_loss: 1.5470 - val_accuracy: 0.4626\n",
            "Epoch 6/100\n",
            "45000/45000 [==============================] - 9s 205us/sample - loss: 1.4419 - accuracy: 0.4964 - val_loss: 1.5535 - val_accuracy: 0.4662\n",
            "Epoch 7/100\n",
            "45000/45000 [==============================] - 9s 192us/sample - loss: 1.3981 - accuracy: 0.5112 - val_loss: 1.5027 - val_accuracy: 0.4772\n",
            "Epoch 8/100\n",
            "45000/45000 [==============================] - 9s 196us/sample - loss: 1.3598 - accuracy: 0.5258 - val_loss: 1.5501 - val_accuracy: 0.4762\n",
            "Epoch 9/100\n",
            "45000/45000 [==============================] - 9s 207us/sample - loss: 1.3212 - accuracy: 0.5420 - val_loss: 1.5219 - val_accuracy: 0.4858\n",
            "Epoch 10/100\n",
            "45000/45000 [==============================] - 10s 232us/sample - loss: 1.2949 - accuracy: 0.5514 - val_loss: 1.4786 - val_accuracy: 0.4968\n",
            "Epoch 11/100\n",
            "45000/45000 [==============================] - 10s 228us/sample - loss: 1.2686 - accuracy: 0.5620 - val_loss: 1.4878 - val_accuracy: 0.4994\n",
            "Epoch 12/100\n",
            "45000/45000 [==============================] - 9s 210us/sample - loss: 1.2334 - accuracy: 0.5747 - val_loss: 1.5364 - val_accuracy: 0.4926\n",
            "Epoch 13/100\n",
            "45000/45000 [==============================] - 10s 215us/sample - loss: 1.2144 - accuracy: 0.5812 - val_loss: 1.4626 - val_accuracy: 0.5140\n",
            "Epoch 14/100\n",
            "45000/45000 [==============================] - 10s 216us/sample - loss: 1.1909 - accuracy: 0.5906 - val_loss: 1.4844 - val_accuracy: 0.5078\n",
            "Epoch 15/100\n",
            "45000/45000 [==============================] - 10s 221us/sample - loss: 1.1606 - accuracy: 0.5990 - val_loss: 1.5233 - val_accuracy: 0.4972\n",
            "Epoch 16/100\n",
            "45000/45000 [==============================] - 10s 221us/sample - loss: 1.1447 - accuracy: 0.6077 - val_loss: 1.4782 - val_accuracy: 0.5060\n",
            "Epoch 17/100\n",
            "45000/45000 [==============================] - 10s 221us/sample - loss: 1.1154 - accuracy: 0.6176 - val_loss: 1.4666 - val_accuracy: 0.5162\n",
            "Epoch 18/100\n",
            "45000/45000 [==============================] - 10s 212us/sample - loss: 1.0949 - accuracy: 0.6258 - val_loss: 1.4978 - val_accuracy: 0.5108\n",
            "Epoch 19/100\n",
            "45000/45000 [==============================] - 9s 207us/sample - loss: 1.0778 - accuracy: 0.6321 - val_loss: 1.5461 - val_accuracy: 0.5130\n",
            "Epoch 20/100\n",
            "45000/45000 [==============================] - 9s 210us/sample - loss: 1.0552 - accuracy: 0.6406 - val_loss: 1.5072 - val_accuracy: 0.5190\n",
            "Epoch 21/100\n",
            "45000/45000 [==============================] - 9s 207us/sample - loss: 1.0361 - accuracy: 0.6492 - val_loss: 1.4997 - val_accuracy: 0.5126\n",
            "Epoch 22/100\n",
            "45000/45000 [==============================] - 9s 209us/sample - loss: 1.0229 - accuracy: 0.6517 - val_loss: 1.5663 - val_accuracy: 0.5066\n",
            "Epoch 23/100\n",
            "45000/45000 [==============================] - 9s 202us/sample - loss: 1.0040 - accuracy: 0.6560 - val_loss: 1.5809 - val_accuracy: 0.5098\n",
            "Epoch 24/100\n",
            "45000/45000 [==============================] - 9s 200us/sample - loss: 0.9848 - accuracy: 0.6656 - val_loss: 1.5104 - val_accuracy: 0.5122\n",
            "Epoch 25/100\n",
            "45000/45000 [==============================] - 9s 206us/sample - loss: 0.9657 - accuracy: 0.6743 - val_loss: 1.6135 - val_accuracy: 0.5196\n",
            "Epoch 26/100\n",
            "45000/45000 [==============================] - 9s 206us/sample - loss: 0.9530 - accuracy: 0.6764 - val_loss: 1.6536 - val_accuracy: 0.5070\n",
            "Epoch 27/100\n",
            "45000/45000 [==============================] - 9s 206us/sample - loss: 0.9296 - accuracy: 0.6857 - val_loss: 1.6331 - val_accuracy: 0.5162\n",
            "Epoch 28/100\n",
            "45000/45000 [==============================] - 9s 204us/sample - loss: 0.9220 - accuracy: 0.6887 - val_loss: 1.5864 - val_accuracy: 0.5104\n",
            "Epoch 29/100\n",
            "45000/45000 [==============================] - 9s 201us/sample - loss: 0.9126 - accuracy: 0.6907 - val_loss: 1.6421 - val_accuracy: 0.5106\n",
            "Epoch 30/100\n",
            "45000/45000 [==============================] - 9s 201us/sample - loss: 0.9011 - accuracy: 0.6963 - val_loss: 1.6751 - val_accuracy: 0.5088\n",
            "Epoch 31/100\n",
            "45000/45000 [==============================] - 9s 206us/sample - loss: 1.4447 - accuracy: 0.5958 - val_loss: 1.5772 - val_accuracy: 0.4806\n",
            "Epoch 32/100\n",
            "45000/45000 [==============================] - 9s 206us/sample - loss: 1.1083 - accuracy: 0.6158 - val_loss: 1.6008 - val_accuracy: 0.4988\n",
            "Epoch 33/100\n",
            "45000/45000 [==============================] - 9s 207us/sample - loss: 1.0031 - accuracy: 0.6533 - val_loss: 1.6117 - val_accuracy: 0.5120\n",
            "5000/5000 [==============================] - 0s 66us/sample - loss: 1.4626 - accuracy: 0.5140\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.462584439086914, 0.514]"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100,\n",
        "          validation_data=(X_valid_scaled, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flm6jZNigel5",
        "outputId": "7f01c184-5870-4dbb-89d6-1f7f7a20cdc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 0s 74us/sample - loss: 1.4626 - accuracy: 0.5140\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.462584439086914, 0.514]"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6xEWzV4gel6"
      },
      "source": [
        "We get 51.4% accuracy, which is better than the original model, but not quite as good as the model using batch normalization. Moreover, it took 13 epochs to reach the best model, which is much faster than both the original model and the BN model, plus each epoch took only 10 seconds, just like the original model. So it's by far the fastest model to train (both in terms of epochs and wall time)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u87l_WzCgel6"
      },
      "source": [
        "### e.\n",
        "*Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoMQSv6wgel6",
        "outputId": "54615410-35e3-4263-a1c2-48508adffb98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "45000/45000 [==============================] - 12s 263us/sample - loss: 1.8763 - accuracy: 0.3330 - val_loss: 1.7595 - val_accuracy: 0.3668\n",
            "Epoch 2/100\n",
            "45000/45000 [==============================] - 10s 219us/sample - loss: 1.6527 - accuracy: 0.4148 - val_loss: 1.7666 - val_accuracy: 0.3808\n",
            "Epoch 3/100\n",
            "45000/45000 [==============================] - 10s 219us/sample - loss: 1.5682 - accuracy: 0.4439 - val_loss: 1.6393 - val_accuracy: 0.4490\n",
            "Epoch 4/100\n",
            "45000/45000 [==============================] - 10s 211us/sample - loss: 1.5030 - accuracy: 0.4698 - val_loss: 1.6028 - val_accuracy: 0.4466\n",
            "Epoch 5/100\n",
            "45000/45000 [==============================] - 9s 209us/sample - loss: 1.4430 - accuracy: 0.4913 - val_loss: 1.5394 - val_accuracy: 0.4562\n",
            "Epoch 6/100\n",
            "45000/45000 [==============================] - 10s 215us/sample - loss: 1.4005 - accuracy: 0.5084 - val_loss: 1.5408 - val_accuracy: 0.4818\n",
            "Epoch 7/100\n",
            "45000/45000 [==============================] - 10s 216us/sample - loss: 1.3541 - accuracy: 0.5298 - val_loss: 1.5236 - val_accuracy: 0.4866\n",
            "Epoch 8/100\n",
            "45000/45000 [==============================] - 10s 214us/sample - loss: 1.3189 - accuracy: 0.5405 - val_loss: 1.5174 - val_accuracy: 0.4926\n",
            "Epoch 9/100\n",
            "45000/45000 [==============================] - 10s 212us/sample - loss: 1.2800 - accuracy: 0.5570 - val_loss: 1.5722 - val_accuracy: 0.4998\n",
            "Epoch 10/100\n",
            "45000/45000 [==============================] - 10s 214us/sample - loss: 1.2512 - accuracy: 0.5656 - val_loss: 1.4974 - val_accuracy: 0.5082\n",
            "Epoch 11/100\n",
            "45000/45000 [==============================] - 9s 203us/sample - loss: 1.2141 - accuracy: 0.5802 - val_loss: 1.6123 - val_accuracy: 0.4916\n",
            "Epoch 12/100\n",
            "45000/45000 [==============================] - 9s 201us/sample - loss: 1.1856 - accuracy: 0.5893 - val_loss: 1.5449 - val_accuracy: 0.5016\n",
            "Epoch 13/100\n",
            "45000/45000 [==============================] - 9s 204us/sample - loss: 1.1602 - accuracy: 0.5978 - val_loss: 1.6241 - val_accuracy: 0.5056\n",
            "Epoch 14/100\n",
            "45000/45000 [==============================] - 9s 199us/sample - loss: 1.1290 - accuracy: 0.6118 - val_loss: 1.6085 - val_accuracy: 0.4936\n",
            "Epoch 15/100\n",
            "45000/45000 [==============================] - 9s 198us/sample - loss: 1.1050 - accuracy: 0.6176 - val_loss: 1.6951 - val_accuracy: 0.4860\n",
            "Epoch 16/100\n",
            "45000/45000 [==============================] - 9s 201us/sample - loss: 1.0786 - accuracy: 0.6293 - val_loss: 1.5806 - val_accuracy: 0.5044\n",
            "Epoch 17/100\n",
            "45000/45000 [==============================] - 10s 212us/sample - loss: 1.0629 - accuracy: 0.6362 - val_loss: 1.5932 - val_accuracy: 0.4970\n",
            "Epoch 18/100\n",
            "45000/45000 [==============================] - 10s 215us/sample - loss: 1.0330 - accuracy: 0.6458 - val_loss: 1.5968 - val_accuracy: 0.5080\n",
            "Epoch 19/100\n",
            "45000/45000 [==============================] - 9s 195us/sample - loss: 1.0104 - accuracy: 0.6488 - val_loss: 1.6166 - val_accuracy: 0.5152\n",
            "Epoch 20/100\n",
            "45000/45000 [==============================] - 9s 206us/sample - loss: 0.9896 - accuracy: 0.6629 - val_loss: 1.6174 - val_accuracy: 0.5154\n",
            "Epoch 21/100\n",
            "45000/45000 [==============================] - 9s 211us/sample - loss: 0.9741 - accuracy: 0.6650 - val_loss: 1.7201 - val_accuracy: 0.5040\n",
            "Epoch 22/100\n",
            "45000/45000 [==============================] - 10s 220us/sample - loss: 0.9475 - accuracy: 0.6769 - val_loss: 1.7498 - val_accuracy: 0.5176\n",
            "Epoch 23/100\n",
            "45000/45000 [==============================] - 10s 216us/sample - loss: 0.9346 - accuracy: 0.6780 - val_loss: 1.7491 - val_accuracy: 0.5020\n",
            "Epoch 24/100\n",
            "45000/45000 [==============================] - 10s 223us/sample - loss: 1.1878 - accuracy: 0.6792 - val_loss: 1.6664 - val_accuracy: 0.4906\n",
            "Epoch 25/100\n",
            "45000/45000 [==============================] - 10s 219us/sample - loss: 0.9851 - accuracy: 0.6646 - val_loss: 1.7358 - val_accuracy: 0.5086\n",
            "Epoch 26/100\n",
            "45000/45000 [==============================] - 10s 220us/sample - loss: 0.9053 - accuracy: 0.6911 - val_loss: 1.8361 - val_accuracy: 0.5094\n",
            "Epoch 27/100\n",
            "45000/45000 [==============================] - 10s 215us/sample - loss: 0.8681 - accuracy: 0.7048 - val_loss: 1.8487 - val_accuracy: 0.5036\n",
            "Epoch 28/100\n",
            "45000/45000 [==============================] - 10s 220us/sample - loss: 0.8460 - accuracy: 0.7132 - val_loss: 1.8516 - val_accuracy: 0.5068\n",
            "Epoch 29/100\n",
            "45000/45000 [==============================] - 10s 223us/sample - loss: 0.8258 - accuracy: 0.7208 - val_loss: 1.9383 - val_accuracy: 0.5094\n",
            "Epoch 30/100\n",
            "45000/45000 [==============================] - 10s 216us/sample - loss: 0.8106 - accuracy: 0.7248 - val_loss: 2.0527 - val_accuracy: 0.4974\n",
            "5000/5000 [==============================] - 0s 71us/sample - loss: 1.4974 - accuracy: 0.5082\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.4974345008850098, 0.5082]"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100,\n",
        "          validation_data=(X_valid_scaled, y_valid),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S08_zaougel7"
      },
      "source": [
        "The model reaches 50.8% accuracy on the validation set. That's very slightly worse than without dropout (51.4%). With an extensive hyperparameter search, it might be possible to do better (I tried dropout rates of 5%, 10%, 20% and 40%, and learning rates 1e-4, 3e-4, 5e-4, and 1e-3), but probably not much better in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLBUL2XJgel7"
      },
      "source": [
        "Let's use MC Dropout now. We will need the `MCAlphaDropout` class we used earlier, so let's just copy it here for convenience:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSVGwvLhgel7"
      },
      "outputs": [],
      "source": [
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjw08SA_gel8"
      },
      "source": [
        "Now let's create a new model, identical to the one we just trained (with the same weights), but with `MCAlphaDropout` dropout layers instead of `AlphaDropout` layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC60gnuGgel8"
      },
      "outputs": [],
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
        "    for layer in model.layers\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6mK9nhfgel8"
      },
      "source": [
        "Then let's add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "821cBNj6gel9"
      },
      "outputs": [],
      "source": [
        "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
        "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
        "    return np.mean(Y_probas, axis=0)\n",
        "\n",
        "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
        "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
        "    return np.argmax(Y_probas, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QodgjFegel9"
      },
      "source": [
        "Now let's make predictions for all the instances in the validation set, and compute the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrBPiLiLgel9",
        "outputId": "a4c549c7-769a-46d6-e726-0f96d7f9cb46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5094"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
        "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpHGj9BGgel-"
      },
      "source": [
        "We only get virtually no accuracy improvement in this case (from 50.8% to 50.9%).\n",
        "\n",
        "So the best model we got in this exercise is the Batch Normalization model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVE-utxogel-"
      },
      "source": [
        "### f.\n",
        "*Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk7El1eNgel-"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=1e-3)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkOLoHdCgel_",
        "outputId": "47cd3ed2-f3e3-4f7e-8556-3b0123633156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 45000 samples\n",
            "45000/45000 [==============================] - 3s 60us/sample - loss: nan - accuracy: 0.1403\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1e-05, 9.999868, 2.0895472, 3.482099260602679]"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size = 128\n",
        "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
        "plot_lr_vs_loss(rates, losses)\n",
        "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxjsuSr_gel_"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=1e-2)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-5fA4lggel_",
        "outputId": "7962f990-e54c-4f27-dc7e-44b3e36acdfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 5000 samples\n",
            "Epoch 1/15\n",
            "45000/45000 [==============================] - 3s 69us/sample - loss: 2.0504 - accuracy: 0.2823 - val_loss: 1.7711 - val_accuracy: 0.3706\n",
            "Epoch 2/15\n",
            "45000/45000 [==============================] - 3s 57us/sample - loss: 1.7626 - accuracy: 0.3766 - val_loss: 1.7751 - val_accuracy: 0.3844\n",
            "Epoch 3/15\n",
            "45000/45000 [==============================] - 3s 59us/sample - loss: 1.6264 - accuracy: 0.4272 - val_loss: 1.6774 - val_accuracy: 0.4216\n",
            "Epoch 4/15\n",
            "45000/45000 [==============================] - 3s 57us/sample - loss: 1.5527 - accuracy: 0.4474 - val_loss: 1.6633 - val_accuracy: 0.4316\n",
            "Epoch 5/15\n",
            "45000/45000 [==============================] - 3s 59us/sample - loss: 1.4997 - accuracy: 0.4701 - val_loss: 1.5909 - val_accuracy: 0.4540\n",
            "Epoch 6/15\n",
            "45000/45000 [==============================] - 3s 60us/sample - loss: 1.4564 - accuracy: 0.4841 - val_loss: 1.5982 - val_accuracy: 0.4624\n",
            "Epoch 7/15\n",
            "45000/45000 [==============================] - 3s 56us/sample - loss: 1.4232 - accuracy: 0.4958 - val_loss: 1.6417 - val_accuracy: 0.4382\n",
            "Epoch 8/15\n",
            "45000/45000 [==============================] - 3s 58us/sample - loss: 1.3530 - accuracy: 0.5199 - val_loss: 1.5050 - val_accuracy: 0.4778\n",
            "Epoch 9/15\n",
            "45000/45000 [==============================] - 3s 57us/sample - loss: 1.2771 - accuracy: 0.5480 - val_loss: 1.5254 - val_accuracy: 0.4928\n",
            "Epoch 10/15\n",
            "45000/45000 [==============================] - 3s 56us/sample - loss: 1.2073 - accuracy: 0.5726 - val_loss: 1.5013 - val_accuracy: 0.5052\n",
            "Epoch 11/15\n",
            "45000/45000 [==============================] - 3s 57us/sample - loss: 1.1380 - accuracy: 0.5948 - val_loss: 1.4941 - val_accuracy: 0.5170\n",
            "Epoch 12/15\n",
            "45000/45000 [==============================] - 3s 56us/sample - loss: 1.0672 - accuracy: 0.6204 - val_loss: 1.5091 - val_accuracy: 0.5106\n",
            "Epoch 13/15\n",
            "45000/45000 [==============================] - 3s 56us/sample - loss: 0.9967 - accuracy: 0.6466 - val_loss: 1.5261 - val_accuracy: 0.5212\n",
            "Epoch 14/15\n",
            "45000/45000 [==============================] - 3s 58us/sample - loss: 0.9301 - accuracy: 0.6712 - val_loss: 1.5437 - val_accuracy: 0.5264\n",
            "Epoch 15/15\n",
            "45000/45000 [==============================] - 3s 59us/sample - loss: 0.8893 - accuracy: 0.6866 - val_loss: 1.5650 - val_accuracy: 0.5276\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 15\n",
        "onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * n_epochs, max_rate=0.05)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[onecycle])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ZuN_o_gemA"
      },
      "source": [
        "One cycle allowed us to train the model in just 15 epochs, each taking only 3 seconds (thanks to the larger batch size). This is over 3 times faster than the fastest model we trained so far. Moreover, we improved the model's performance (from 50.8% to 52.8%). The batch normalized model reaches a slightly better performance, but it's much slower to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTeW8O4PgemA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nav_menu": {
      "height": "360px",
      "width": "416px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BDNhKZ0agekN",
        "4HjBt6w8gekQ",
        "hszPZNSWgek2",
        "fGrV5Gl_gek4",
        "eDvq_OYogek5",
        "pGGMvDqdgelF",
        "FUH1xtdJgelG",
        "6j9oe-nSgelH",
        "VuKYE4DsgelI",
        "_g0vnEhhgelI",
        "dhD9qFlmgelJ",
        "jBd_8RLvgelK",
        "LWqTmg0mgelL",
        "29YveTSVgelL",
        "3wn8hn5EgelN",
        "b63bmNl0gelV",
        "zaoBJRXIgelZ",
        "sVEBwFbRgelb",
        "-OTCT-V5gele",
        "6op3Pprigelh",
        "8hHs1VUEgeli",
        "Ln-UZjSmgelj",
        "fTUcMXlggelm",
        "sV6LNFsNgelt",
        "bYitULAAgelu",
        "t93Bvp4-gelv",
        "JKnzA-sugelv",
        "90nJkbNNgelw",
        "0qbfKNgYgel3",
        "pd7-SCVygel4",
        "u87l_WzCgel6",
        "bVE-utxogel-"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}